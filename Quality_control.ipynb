{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "3fa1a89f-68fc-4520-8328-8a00efdc8b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn import model_selection\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics._scorer import make_scorer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from scipy.spatial.distance import hamming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "id": "64362e3b-0dbf-40b7-9a6e-cb5752f8bfb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_feature_imp(X, y, title='', plot_imp=False):\n",
    "    '''\n",
    "        Подсчет значимости для каждого признака из X \n",
    "    '''\n",
    "    model = XGBClassifier(\n",
    "            tree_method=\"gpu_hist\",\n",
    "            enable_categorical=True,\n",
    "            use_label_encoder=False,\n",
    "        )\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    f_importance = model.feature_importances_\n",
    "    f_importance\n",
    "    \n",
    "    if plot_imp:\n",
    "        boxplot_importance(f_importance, title)\n",
    "        \n",
    "    return f_importance\n",
    "\n",
    "def boxplot_importance(features, title=''):\n",
    "    '''\n",
    "        Построение ящика с усами для каждого признака\n",
    "        Где: features - массив значимостей для каждого признака\n",
    "        title - заголовок ящика с усами\n",
    "    '''\n",
    "    fig, axes = plt.subplots(1, 2, sharex=True, sharey=True)\n",
    "    fig.set_figheight(5)\n",
    "    fig.set_figwidth(14)\n",
    "    axes[0].boxplot(features)\n",
    "    axes[0].grid()\n",
    "    axes[0].set_title(title)\n",
    "    \n",
    "def plot_metric_dep_f_count(num_x, num_y, cat_x, cat_y, time_x, time_y):\n",
    "    '''\n",
    "        Строит графики зависимости метрики от числа признаков\n",
    "        для категориальных, числовых и времянных признаков\n",
    "    '''\n",
    "    fig, axes = plt.subplots(1, 3, sharex=False, sharey=True)\n",
    "    fig.set_figheight(5)\n",
    "    fig.set_figwidth(14)\n",
    "    axes[0].plot(num_x, num_y)\n",
    "    axes[0].grid()\n",
    "    axes[0].set_title('Значение метрики в\\n зависимости от числа\\nчисловых признаков')\n",
    "\n",
    "    axes[1].plot(cat_x, cat_y)\n",
    "    axes[1].grid()\n",
    "    axes[1].set_title('Значение метрики в\\n зависимости от числа\\nкатегориальных признаков')\n",
    "    \n",
    "    axes[2].plot(time_x, time_y)\n",
    "    axes[2].grid()\n",
    "    axes[2].set_title('Значение метрики в\\n зависимости от числа\\nвремянных признаков')\n",
    "    \n",
    "    return {'countmax numeric': np.argmax(num_y) + 1,\n",
    "            'countmax categorical': np.argmax(cat_y) + 1,\n",
    "            'countmax time': np.argmax(time_y) + 1,\n",
    "           }\n",
    "    \n",
    "    \n",
    "    \n",
    "def get_sorted_labels(labels, features_imp):\n",
    "    '''\n",
    "        Вернет массив меток признаков, отсортированных по убыванию значимости\n",
    "        соответствующего признака\n",
    "    '''\n",
    "    return pd.Series(data=features_imp, index=labels).sort_values(ascending=False).index\n",
    "\n",
    "\n",
    "def metrics_on_feature_count(X, y, max_count):\n",
    "    '''\n",
    "        Выполняет подсчет зависимости меторики от числа признаков\n",
    "    '''\n",
    "    metrics = np.zeros(max_count)\n",
    "    for count in range(1, max_count + 1):\n",
    "        model = XGBClassifier(\n",
    "            tree_method=\"gpu_hist\",\n",
    "            enable_categorical=True,\n",
    "            use_label_encoder=False,\n",
    "        )\n",
    "        X_train = X[:X.shape[0] // 2, :count]\n",
    "        y_train = y[:X.shape[0] // 2]\n",
    "        X_test = X[X.shape[0] // 2:, :count]\n",
    "        y_test = y[X.shape[0] // 2:]\n",
    "        model.fit(X_train, y_train)\n",
    "        y_pred = model.predict(X_test)\n",
    "        metrics[count - 1] = show_metrics(y_test, y_pred, get_corrcoef=True)\n",
    "    return metrics\n",
    "    \n",
    "def show_metrics(y_true, y_pred, get_corrcoef=False):\n",
    "    '''\n",
    "        Если get_corrcoef = False => выполнит расчет всех метрик \n",
    "        Если get_corrcoef = True => вернет только значение MCC\n",
    "    '''\n",
    "    if get_corrcoef:\n",
    "        return metrics.matthews_corrcoef(y_true, y_pred)\n",
    "    \n",
    "    data = {\n",
    "        'accuracy': [metrics.accuracy_score(y_true, y_pred)],\n",
    "        'matthews_corrcoef': [metrics.matthews_corrcoef(y_true, y_pred)],\n",
    "        'roc_auc_score': [metrics.roc_auc_score(y_true, y_pred)],\n",
    "        'precision': [metrics.precision_score(y_true, y_pred)],\n",
    "        'recall': [metrics.recall_score(y_true, y_pred)],\n",
    "        'f1_score': [metrics.f1_score(y_true, y_pred)]\n",
    "    }\n",
    "    \n",
    "    return pd.DataFrame(data).round(3)\n",
    "\n",
    "\n",
    "def plot_roc(y_true, y_pred, y_pred_proba):\n",
    "    '''\n",
    "        Сторит кривую ROC\n",
    "    '''\n",
    "    fp, tp, _ = metrics.roc_curve(y_true,  y_pred_proba)\n",
    "    score = np.round(metrics.roc_auc_score(y_true, y_pred), 3)\n",
    "    plt.plot(fp, tp, label='roc auc-оценка = ' + str(score), color='blue')\n",
    "    plt.plot([0, 1], [0, 1], label='нулевая эффективность', linestyle='dashed', color='black')\n",
    "    plt.xlabel(\"Доля ложных положительных классификаций\")\n",
    "    plt.ylabel(\"Доля верных положительных классификаций\")\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "def plot_pr_rec_curve(y_true, y_pred, y_pred_proba):\n",
    "    '''\n",
    "        Сторит кривую Precision Recall \n",
    "    '''\n",
    "    precision, recall, _ = metrics.precision_recall_curve(y_true,  y_pred_proba)\n",
    "    score = np.round(metrics.auc(x=recall, y=precision), 3)\n",
    "    plt.plot(recall, precision, label='площадь под графиком = ' + str(score), color='blue')\n",
    "    plt.plot([0, 1], [0, 0], label='нулевая эффективность', linestyle='dashed', color='black')\n",
    "    plt.xlabel(\"recall\")\n",
    "    plt.ylabel(\"precision\")\n",
    "    plt.grid()\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "def fit_and_find_hpar(model, param_dis, X, y, n_splits=10, test_size=0.3):\n",
    "    '''\n",
    "        Выполняет подбор гиперпараметров\n",
    "    '''\n",
    "    np.random.seed=334\n",
    "    split_strategy = model_selection.StratifiedShuffleSplit(n_splits=n_splits, test_size=test_size)\n",
    "    \n",
    "     \n",
    "    search_model = RandomizedSearchCV(estimator=model, \n",
    "                            param_distributions=param_dis, \n",
    "                            scoring=make_scorer(metrics.matthews_corrcoef), \n",
    "                            cv=split_strategy,\n",
    "                            )\n",
    "    \n",
    "    search_model.fit(X, y)\n",
    "    return search_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba479212-4f35-4145-999d-421e027bb472",
   "metadata": {},
   "source": [
    "# Описание предметной области \n",
    "Во время производственного процесса деталь проходит через разные этапы изготовления, на каждом из которых измеряются определенные характеристики детали. В результате прохождения детали через производственный процесс специальный сотрудник выполняет контроль качества детали (по данным характеристикам) и определяет является ли деталь бракованной, или нет. Детали присваивается id и ее характеристики записываются в виде строки в таблицу. Каждый столбец соответствует своей характеристике данной детали (каждая строка соответствует своей детали). В самом последнем столбце указывается единица, если деталь не прошла контроль качества, и ноль, если контроль качества пройден. Подобным образом формируется таблица, которая является источником данных для будущей модели и называется **датасетом**.\n",
    "\n",
    "Каждую измеренную характеристику (соответствующую столбцу) будем называть **признаком**, саму деталь **объектом**, а ее результат прохождения контроля качества – **меткой** (последний столбец таблицы) или **таргетом**.\n",
    "\n",
    "**Цель данного проекта** - построение и тестирование модели для предсказания прохождения деталью контроля качества.\n",
    "\n",
    "Датасет включает в себя три таблицы в формате csv: train_numeric, train_categorical, train_date (для чилсовых, категориальных, временных признаков соответственно)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b29a31a5-6681-4abe-98c0-669162ff91a0",
   "metadata": {},
   "source": [
    "# Исследование данных"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385634aa-c08a-4d0a-a6c0-72d96d692ad2",
   "metadata": {},
   "source": [
    "Выполним чтение таблиц с числовыми и категориальными признаками"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "51c86790-f546-43f3-aa5b-4c21187d4d79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 970)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "df_num = pd.read_csv('datasets/train_numeric.csv', sep=',', nrows=200000, dtype='float64')\n",
    "df_cat = pd.read_csv('datasets/train_categorical.csv', sep=',', nrows=200000, dtype='category')\n",
    "df_num.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "0dbed0e7-9a64-4f8f-afb5-badc922324d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 2141)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "3ab13405-c253-4c5e-af58-c4bacf754e29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>L0_S0_F0</th>\n",
       "      <th>L0_S0_F2</th>\n",
       "      <th>L0_S0_F4</th>\n",
       "      <th>L0_S0_F6</th>\n",
       "      <th>L0_S0_F8</th>\n",
       "      <th>L0_S0_F10</th>\n",
       "      <th>L0_S0_F12</th>\n",
       "      <th>L0_S0_F14</th>\n",
       "      <th>L0_S0_F16</th>\n",
       "      <th>...</th>\n",
       "      <th>L3_S50_F4245</th>\n",
       "      <th>L3_S50_F4247</th>\n",
       "      <th>L3_S50_F4249</th>\n",
       "      <th>L3_S50_F4251</th>\n",
       "      <th>L3_S50_F4253</th>\n",
       "      <th>L3_S51_F4256</th>\n",
       "      <th>L3_S51_F4258</th>\n",
       "      <th>L3_S51_F4260</th>\n",
       "      <th>L3_S51_F4262</th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>0.030</td>\n",
       "      <td>-0.034</td>\n",
       "      <td>-0.197</td>\n",
       "      <td>-0.179</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.116</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>-0.032</td>\n",
       "      <td>0.020</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.088</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.003</td>\n",
       "      <td>-0.052</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.025</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>-0.072</td>\n",
       "      <td>-0.225</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.0</td>\n",
       "      <td>-0.036</td>\n",
       "      <td>-0.064</td>\n",
       "      <td>0.294</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.128</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.0</td>\n",
       "      <td>-0.055</td>\n",
       "      <td>-0.086</td>\n",
       "      <td>0.294</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.168</td>\n",
       "      <td>-0.169</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 970 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Id  L0_S0_F0  L0_S0_F2  L0_S0_F4  L0_S0_F6  L0_S0_F8  L0_S0_F10  \\\n",
       "0   4.0     0.030    -0.034    -0.197    -0.179     0.118      0.116   \n",
       "1   6.0       NaN       NaN       NaN       NaN       NaN        NaN   \n",
       "2   7.0     0.088     0.086     0.003    -0.052     0.161      0.025   \n",
       "3   9.0    -0.036    -0.064     0.294     0.330     0.074      0.161   \n",
       "4  11.0    -0.055    -0.086     0.294     0.330     0.118      0.025   \n",
       "\n",
       "   L0_S0_F12  L0_S0_F14  L0_S0_F16  ...  L3_S50_F4245  L3_S50_F4247  \\\n",
       "0     -0.015     -0.032      0.020  ...           NaN           NaN   \n",
       "1        NaN        NaN        NaN  ...           NaN           NaN   \n",
       "2     -0.015     -0.072     -0.225  ...           NaN           NaN   \n",
       "3      0.022      0.128     -0.026  ...           NaN           NaN   \n",
       "4      0.030      0.168     -0.169  ...           NaN           NaN   \n",
       "\n",
       "   L3_S50_F4249  L3_S50_F4251  L3_S50_F4253  L3_S51_F4256  L3_S51_F4258  \\\n",
       "0           NaN           NaN           NaN           NaN           NaN   \n",
       "1           NaN           NaN           NaN           NaN           NaN   \n",
       "2           NaN           NaN           NaN           NaN           NaN   \n",
       "3           NaN           NaN           NaN           NaN           NaN   \n",
       "4           NaN           NaN           NaN           NaN           NaN   \n",
       "\n",
       "   L3_S51_F4260  L3_S51_F4262  Response  \n",
       "0           NaN           NaN       0.0  \n",
       "1           NaN           NaN       0.0  \n",
       "2           NaN           NaN       0.0  \n",
       "3           NaN           NaN       0.0  \n",
       "4           NaN           NaN       0.0  \n",
       "\n",
       "[5 rows x 970 columns]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_num.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "3f35beb1-e45e-4623-8f24-ce2a1307d8c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>L0_S1_F25</th>\n",
       "      <th>L0_S1_F27</th>\n",
       "      <th>L0_S1_F29</th>\n",
       "      <th>L0_S1_F31</th>\n",
       "      <th>L0_S2_F33</th>\n",
       "      <th>L0_S2_F35</th>\n",
       "      <th>L0_S2_F37</th>\n",
       "      <th>L0_S2_F39</th>\n",
       "      <th>L0_S2_F41</th>\n",
       "      <th>...</th>\n",
       "      <th>L3_S49_F4225</th>\n",
       "      <th>L3_S49_F4227</th>\n",
       "      <th>L3_S49_F4229</th>\n",
       "      <th>L3_S49_F4230</th>\n",
       "      <th>L3_S49_F4232</th>\n",
       "      <th>L3_S49_F4234</th>\n",
       "      <th>L3_S49_F4235</th>\n",
       "      <th>L3_S49_F4237</th>\n",
       "      <th>L3_S49_F4239</th>\n",
       "      <th>L3_S49_F4240</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2141 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id L0_S1_F25 L0_S1_F27 L0_S1_F29 L0_S1_F31 L0_S2_F33 L0_S2_F35 L0_S2_F37  \\\n",
       "0   4       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "1   6       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "2   7       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "3   9       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "4  11       NaN       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "\n",
       "  L0_S2_F39 L0_S2_F41  ... L3_S49_F4225 L3_S49_F4227 L3_S49_F4229  \\\n",
       "0       NaN       NaN  ...          NaN          NaN          NaN   \n",
       "1       NaN       NaN  ...          NaN          NaN          NaN   \n",
       "2       NaN       NaN  ...          NaN          NaN          NaN   \n",
       "3       NaN       NaN  ...          NaN          NaN          NaN   \n",
       "4       NaN       NaN  ...          NaN          NaN          NaN   \n",
       "\n",
       "  L3_S49_F4230 L3_S49_F4232 L3_S49_F4234 L3_S49_F4235 L3_S49_F4237  \\\n",
       "0          NaN          NaN          NaN          NaN          NaN   \n",
       "1          NaN          NaN          NaN          NaN          NaN   \n",
       "2          NaN          NaN          NaN          NaN          NaN   \n",
       "3          NaN          NaN          NaN          NaN          NaN   \n",
       "4          NaN          NaN          NaN          NaN          NaN   \n",
       "\n",
       "  L3_S49_F4239 L3_S49_F4240  \n",
       "0          NaN          NaN  \n",
       "1          NaN          NaN  \n",
       "2          NaN          NaN  \n",
       "3          NaN          NaN  \n",
       "4          NaN          NaN  \n",
       "\n",
       "[5 rows x 2141 columns]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f51ab041-005c-4210-8312-97f683ccfbee",
   "metadata": {},
   "source": [
    "Видно, что в исходных данных присутствует большое количество пропусков. Также мы имеем дело с крайне большим количеством признаков (общее число столбцов больше трех тысяч).\n",
    "\n",
    "Вызовем метод describe для таблицы с числовыми данными. Он выведет следующие статистические величины для каждого столбца: count – количество значений (не включая пропуски); mean – среднее арифметическое; std – стандартное отклонение; min, max – минимальное и максимальное значение выборки; числа со знаком % - квартили (значения признака, которые делят упорядоченное множество элементов столбца на 4 равные части)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "cca2f2ef-b01b-4877-ad46-5aa6a7300b1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>L0_S0_F0</th>\n",
       "      <th>L0_S0_F2</th>\n",
       "      <th>L0_S0_F4</th>\n",
       "      <th>L0_S0_F6</th>\n",
       "      <th>L0_S0_F8</th>\n",
       "      <th>L0_S0_F10</th>\n",
       "      <th>L0_S0_F12</th>\n",
       "      <th>L0_S0_F14</th>\n",
       "      <th>L0_S0_F16</th>\n",
       "      <th>...</th>\n",
       "      <th>L3_S50_F4245</th>\n",
       "      <th>L3_S50_F4247</th>\n",
       "      <th>L3_S50_F4249</th>\n",
       "      <th>L3_S50_F4251</th>\n",
       "      <th>L3_S50_F4253</th>\n",
       "      <th>L3_S51_F4256</th>\n",
       "      <th>L3_S51_F4258</th>\n",
       "      <th>L3_S51_F4260</th>\n",
       "      <th>L3_S51_F4262</th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200000.000000</td>\n",
       "      <td>115932.000000</td>\n",
       "      <td>115932.000000</td>\n",
       "      <td>115932.000000</td>\n",
       "      <td>115932.000000</td>\n",
       "      <td>115932.000000</td>\n",
       "      <td>115932.000000</td>\n",
       "      <td>115932.000000</td>\n",
       "      <td>115932.000000</td>\n",
       "      <td>115932.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5316.000000</td>\n",
       "      <td>5316.000000</td>\n",
       "      <td>5316.000000</td>\n",
       "      <td>5316.000000</td>\n",
       "      <td>5316.000000</td>\n",
       "      <td>10383.000000</td>\n",
       "      <td>10383.000000</td>\n",
       "      <td>10383.000000</td>\n",
       "      <td>10383.000000</td>\n",
       "      <td>200000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>200029.947135</td>\n",
       "      <td>-0.001997</td>\n",
       "      <td>-0.002514</td>\n",
       "      <td>-0.000876</td>\n",
       "      <td>-0.000985</td>\n",
       "      <td>0.000722</td>\n",
       "      <td>0.003152</td>\n",
       "      <td>0.000258</td>\n",
       "      <td>0.001459</td>\n",
       "      <td>-0.001297</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000002</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>0.000478</td>\n",
       "      <td>0.000155</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>-0.000008</td>\n",
       "      <td>0.000201</td>\n",
       "      <td>0.000370</td>\n",
       "      <td>0.000049</td>\n",
       "      <td>0.005645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>115402.589920</td>\n",
       "      <td>0.080453</td>\n",
       "      <td>0.093157</td>\n",
       "      <td>0.210657</td>\n",
       "      <td>0.210733</td>\n",
       "      <td>0.093107</td>\n",
       "      <td>0.162213</td>\n",
       "      <td>0.019291</td>\n",
       "      <td>0.103561</td>\n",
       "      <td>0.115565</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000045</td>\n",
       "      <td>0.000397</td>\n",
       "      <td>0.018767</td>\n",
       "      <td>0.001966</td>\n",
       "      <td>0.250023</td>\n",
       "      <td>0.000091</td>\n",
       "      <td>0.013882</td>\n",
       "      <td>0.010551</td>\n",
       "      <td>0.000922</td>\n",
       "      <td>0.074921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>-0.565000</td>\n",
       "      <td>-0.474000</td>\n",
       "      <td>-0.397000</td>\n",
       "      <td>-0.416000</td>\n",
       "      <td>-0.404000</td>\n",
       "      <td>-0.612000</td>\n",
       "      <td>-0.052000</td>\n",
       "      <td>-0.232000</td>\n",
       "      <td>-0.408000</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>-0.001000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>100148.500000</td>\n",
       "      <td>-0.055000</td>\n",
       "      <td>-0.064000</td>\n",
       "      <td>-0.179000</td>\n",
       "      <td>-0.179000</td>\n",
       "      <td>-0.056000</td>\n",
       "      <td>-0.066000</td>\n",
       "      <td>-0.015000</td>\n",
       "      <td>-0.072000</td>\n",
       "      <td>-0.082000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>200353.000000</td>\n",
       "      <td>0.003000</td>\n",
       "      <td>0.004000</td>\n",
       "      <td>-0.033000</td>\n",
       "      <td>-0.034000</td>\n",
       "      <td>0.031000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-0.032000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>299819.500000</td>\n",
       "      <td>0.056000</td>\n",
       "      <td>0.063000</td>\n",
       "      <td>0.294000</td>\n",
       "      <td>0.294000</td>\n",
       "      <td>0.074000</td>\n",
       "      <td>0.116000</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>0.088000</td>\n",
       "      <td>0.076000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>399899.000000</td>\n",
       "      <td>0.278000</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.567000</td>\n",
       "      <td>0.566000</td>\n",
       "      <td>0.422000</td>\n",
       "      <td>0.388000</td>\n",
       "      <td>0.422000</td>\n",
       "      <td>0.528000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>0.021000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.057000</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>0.001000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.509000</td>\n",
       "      <td>0.046000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 970 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Id       L0_S0_F0       L0_S0_F2       L0_S0_F4  \\\n",
       "count  200000.000000  115932.000000  115932.000000  115932.000000   \n",
       "mean   200029.947135      -0.001997      -0.002514      -0.000876   \n",
       "std    115402.589920       0.080453       0.093157       0.210657   \n",
       "min         4.000000      -0.565000      -0.474000      -0.397000   \n",
       "25%    100148.500000      -0.055000      -0.064000      -0.179000   \n",
       "50%    200353.000000       0.003000       0.004000      -0.033000   \n",
       "75%    299819.500000       0.056000       0.063000       0.294000   \n",
       "max    399899.000000       0.278000       0.280000       0.567000   \n",
       "\n",
       "            L0_S0_F6       L0_S0_F8      L0_S0_F10      L0_S0_F12  \\\n",
       "count  115932.000000  115932.000000  115932.000000  115932.000000   \n",
       "mean       -0.000985       0.000722       0.003152       0.000258   \n",
       "std         0.210733       0.093107       0.162213       0.019291   \n",
       "min        -0.416000      -0.404000      -0.612000      -0.052000   \n",
       "25%        -0.179000      -0.056000      -0.066000      -0.015000   \n",
       "50%        -0.034000       0.031000       0.070000       0.000000   \n",
       "75%         0.294000       0.074000       0.116000       0.015000   \n",
       "max         0.566000       0.422000       0.388000       0.422000   \n",
       "\n",
       "           L0_S0_F14      L0_S0_F16  ...  L3_S50_F4245  L3_S50_F4247  \\\n",
       "count  115932.000000  115932.000000  ...   5316.000000   5316.000000   \n",
       "mean        0.001459      -0.001297  ...     -0.000002      0.000015   \n",
       "std         0.103561       0.115565  ...      0.000045      0.000397   \n",
       "min        -0.232000      -0.408000  ...     -0.001000      0.000000   \n",
       "25%        -0.072000      -0.082000  ...      0.000000      0.000000   \n",
       "50%        -0.032000       0.000000  ...      0.000000      0.000000   \n",
       "75%         0.088000       0.076000  ...      0.000000      0.000000   \n",
       "max         0.528000       0.500000  ...      0.001000      0.021000   \n",
       "\n",
       "       L3_S50_F4249  L3_S50_F4251  L3_S50_F4253  L3_S51_F4256  L3_S51_F4258  \\\n",
       "count   5316.000000   5316.000000   5316.000000  10383.000000  10383.000000   \n",
       "mean       0.000478      0.000155      0.000188     -0.000008      0.000201   \n",
       "std        0.018767      0.001966      0.250023      0.000091      0.013882   \n",
       "min        0.000000      0.000000     -0.250000     -0.001000      0.000000   \n",
       "25%        0.000000      0.000000     -0.250000      0.000000      0.000000   \n",
       "50%        0.000000      0.000000      0.250000      0.000000      0.000000   \n",
       "75%        0.000000      0.000000      0.250000      0.000000      0.000000   \n",
       "max        1.000000      0.057000      0.250000      0.001000      1.000000   \n",
       "\n",
       "       L3_S51_F4260  L3_S51_F4262       Response  \n",
       "count  10383.000000  10383.000000  200000.000000  \n",
       "mean       0.000370      0.000049       0.005645  \n",
       "std        0.010551      0.000922       0.074921  \n",
       "min        0.000000      0.000000       0.000000  \n",
       "25%        0.000000      0.000000       0.000000  \n",
       "50%        0.000000      0.000000       0.000000  \n",
       "75%        0.000000      0.000000       0.000000  \n",
       "max        0.509000      0.046000       1.000000  \n",
       "\n",
       "[8 rows x 970 columns]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_num.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2357eea6-f731-4a6e-91e4-ca8497ed8d04",
   "metadata": {},
   "source": [
    "Невооруженным глазом можно заметить что количество объектов (поле id строки count) в среднем почти в 2 раза (иногда и в 4 раза) больше количества непропущенных значений в каждом из столбцов датафрейма. Получается, что основную часть входных данных составляют пропуски. В такой ситуации мы не можем просто взять и удалить строки с пропусками, так как это приведет к потере основной части данных.\n",
    "\n",
    "Вспомним, что каждый объект таблицы соответствует своей метке. В данном случае число возможных меток – 2: либо деталь прошла контроль качества (метка = 0), либо – нет (метка = 1). Посчитаем количество объектов в каждом из классов и сравним полученные значения между собой."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "4c095666-f88d-4d18-b210-35b406a23ab5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Response\n",
       "0.0    198871\n",
       "1.0      1129\n",
       "Name: Id, dtype: int64"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_targets = df_num.groupby(by='Response')['Id'].count()\n",
    "count_targets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4e853c-d5f7-4656-b9be-1d89095c0038",
   "metadata": {},
   "source": [
    "Количество объектов не одинаково в обоих классах. Более того, Число объектов нулевого класса превосходит число объектов единичного почти в 175 раз. Подобные выборки (когда количество объектов в классах различается сильно) называются несбалансированными."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5c6efb-33f7-4d75-8988-ae9481735405",
   "metadata": {},
   "source": [
    "## Нахождение значимых категориальных признаков "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "8c4c0dbd-f230-4245-b03c-80d8b29e3189",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>L0_S1_F25</th>\n",
       "      <th>L0_S1_F27</th>\n",
       "      <th>L0_S1_F29</th>\n",
       "      <th>L0_S1_F31</th>\n",
       "      <th>L0_S2_F33</th>\n",
       "      <th>L0_S2_F35</th>\n",
       "      <th>L0_S2_F37</th>\n",
       "      <th>L0_S2_F39</th>\n",
       "      <th>L0_S2_F41</th>\n",
       "      <th>...</th>\n",
       "      <th>L3_S49_F4225</th>\n",
       "      <th>L3_S49_F4227</th>\n",
       "      <th>L3_S49_F4229</th>\n",
       "      <th>L3_S49_F4230</th>\n",
       "      <th>L3_S49_F4232</th>\n",
       "      <th>L3_S49_F4234</th>\n",
       "      <th>L3_S49_F4235</th>\n",
       "      <th>L3_S49_F4237</th>\n",
       "      <th>L3_S49_F4239</th>\n",
       "      <th>L3_S49_F4240</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>399894</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>399896</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>399897</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>399898</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>399899</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows × 2141 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id L0_S1_F25 L0_S1_F27 L0_S1_F29 L0_S1_F31 L0_S2_F33 L0_S2_F35  \\\n",
       "0            4       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "1            6       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "2            7       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "3            9       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "4           11       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "199995  399894       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "199996  399896       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "199997  399897       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "199998  399898       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "199999  399899       NaN       NaN       NaN       NaN       NaN       NaN   \n",
       "\n",
       "       L0_S2_F37 L0_S2_F39 L0_S2_F41  ... L3_S49_F4225 L3_S49_F4227  \\\n",
       "0            NaN       NaN       NaN  ...          NaN          NaN   \n",
       "1            NaN       NaN       NaN  ...          NaN          NaN   \n",
       "2            NaN       NaN       NaN  ...          NaN          NaN   \n",
       "3            NaN       NaN       NaN  ...          NaN          NaN   \n",
       "4            NaN       NaN       NaN  ...          NaN          NaN   \n",
       "...          ...       ...       ...  ...          ...          ...   \n",
       "199995       NaN       NaN       NaN  ...          NaN          NaN   \n",
       "199996       NaN       NaN       NaN  ...          NaN          NaN   \n",
       "199997       NaN       NaN       NaN  ...          NaN          NaN   \n",
       "199998       NaN       NaN       NaN  ...          NaN          NaN   \n",
       "199999       NaN       NaN       NaN  ...          NaN          NaN   \n",
       "\n",
       "       L3_S49_F4229 L3_S49_F4230 L3_S49_F4232 L3_S49_F4234 L3_S49_F4235  \\\n",
       "0               NaN          NaN          NaN          NaN          NaN   \n",
       "1               NaN          NaN          NaN          NaN          NaN   \n",
       "2               NaN          NaN          NaN          NaN          NaN   \n",
       "3               NaN          NaN          NaN          NaN          NaN   \n",
       "4               NaN          NaN          NaN          NaN          NaN   \n",
       "...             ...          ...          ...          ...          ...   \n",
       "199995          NaN          NaN          NaN          NaN          NaN   \n",
       "199996          NaN          NaN          NaN          NaN          NaN   \n",
       "199997          NaN          NaN          NaN          NaN          NaN   \n",
       "199998          NaN          NaN          NaN          NaN          NaN   \n",
       "199999          NaN          NaN          NaN          NaN          NaN   \n",
       "\n",
       "       L3_S49_F4237 L3_S49_F4239 L3_S49_F4240  \n",
       "0               NaN          NaN          NaN  \n",
       "1               NaN          NaN          NaN  \n",
       "2               NaN          NaN          NaN  \n",
       "3               NaN          NaN          NaN  \n",
       "4               NaN          NaN          NaN  \n",
       "...             ...          ...          ...  \n",
       "199995          NaN          NaN          NaN  \n",
       "199996          NaN          NaN          NaN  \n",
       "199997          NaN          NaN          NaN  \n",
       "199998          NaN          NaN          NaN  \n",
       "199999          NaN          NaN          NaN  \n",
       "\n",
       "[200000 rows x 2141 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bb065d8-c536-4bdc-8cfb-ae21172ba027",
   "metadata": {},
   "source": [
    "Особенно большое количество признаков встречается в таблице с категориальными данными – 2141 признак."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "332c601c-6b95-4d59-876f-a0d9a039364f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat.drop('Id', inplace=True, axis=1)\n",
    "df_num.drop('Id', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "6b6e6802-dc10-41e3-8b19-016d6033fe21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['L0_S1_F25', 'L0_S1_F27', 'L0_S1_F29', 'L0_S1_F31', 'L0_S2_F33',\n",
       "       'L0_S2_F35', 'L0_S2_F37', 'L0_S2_F39', 'L0_S2_F41', 'L0_S2_F43',\n",
       "       ...\n",
       "       'L3_S49_F4225', 'L3_S49_F4227', 'L3_S49_F4229', 'L3_S49_F4230',\n",
       "       'L3_S49_F4232', 'L3_S49_F4234', 'L3_S49_F4235', 'L3_S49_F4237',\n",
       "       'L3_S49_F4239', 'L3_S49_F4240'],\n",
       "      dtype='object', length=2140)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b965f951-51d4-4380-ae81-f0b7d07602aa",
   "metadata": {},
   "source": [
    "Для каждого столбца оценим долю непропущенных элементов – объект freq."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "b120f599-1875-48b9-bd89-7dcc7f7b5ad9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>segment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>L0_S1_F25</th>\n",
       "      <td>0.000040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L0_S1_F27</th>\n",
       "      <td>0.000040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L0_S1_F29</th>\n",
       "      <td>0.000040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L0_S1_F31</th>\n",
       "      <td>0.000040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L0_S2_F33</th>\n",
       "      <td>0.000195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L3_S49_F4234</th>\n",
       "      <td>0.000020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L3_S49_F4235</th>\n",
       "      <td>0.000035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L3_S49_F4237</th>\n",
       "      <td>0.000035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L3_S49_F4239</th>\n",
       "      <td>0.000020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L3_S49_F4240</th>\n",
       "      <td>0.000035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2140 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               segment\n",
       "L0_S1_F25     0.000040\n",
       "L0_S1_F27     0.000040\n",
       "L0_S1_F29     0.000040\n",
       "L0_S1_F31     0.000040\n",
       "L0_S2_F33     0.000195\n",
       "...                ...\n",
       "L3_S49_F4234  0.000020\n",
       "L3_S49_F4235  0.000035\n",
       "L3_S49_F4237  0.000035\n",
       "L3_S49_F4239  0.000020\n",
       "L3_S49_F4240  0.000035\n",
       "\n",
       "[2140 rows x 1 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = pd.DataFrame((df_cat.count(axis=0) / df_cat.shape[0]), columns=['segment'])\n",
    "freq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b2dd9e0-5799-487d-a3de-acd4c371a150",
   "metadata": {},
   "source": [
    "Построим «ящик с усами» по этим данным."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d6b8f711-1c80-4fe2-90d8-3e7f02875681",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:ylabel='доли непропущенных элементов для каждого столбца'>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.ylabel('доли непропущенных элементов для каждого столбца')\n",
    "freq.boxplot(column='segment')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d88025ed-d076-4283-861d-616e72e1f1eb",
   "metadata": {},
   "source": [
    "Как видно основная часть категориальных столбцов датасета практически полностью состоит из пропущенных ячеек – доля непропущенных значений в них меньше 0.2 (поэтому ящик сильно «сплющен» возле нулевого значения). Исходя из этого можно сделать предположение, что данные столбцы не оказывают существенного влияния на целевую переменную и их можно не учитывать. Установим порог для долей непропущенных элементов равный 0.60. Выведем названия признаков, удовлетворяющих порогу."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "5a0c28c4-f50f-4fe1-afab-4f6fbc7081ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['L3_S29_F3317', 'L3_S29_F3320', 'L3_S29_F3323', 'L3_S29_F3326',\n",
       "       'L3_S29_F3329', 'L3_S29_F3332', 'L3_S29_F3335', 'L3_S29_F3338',\n",
       "       'L3_S29_F3341', 'L3_S29_F3344', 'L3_S29_F3347', 'L3_S29_F3350',\n",
       "       'L3_S29_F3353', 'L3_S29_F3356', 'L3_S29_F3359', 'L3_S29_F3362',\n",
       "       'L3_S29_F3364', 'L3_S29_F3366', 'L3_S29_F3369', 'L3_S29_F3372',\n",
       "       'L3_S29_F3375', 'L3_S29_F3378', 'L3_S29_F3381', 'L3_S29_F3384',\n",
       "       'L3_S29_F3387', 'L3_S29_F3390', 'L3_S29_F3392', 'L3_S29_F3394',\n",
       "       'L3_S29_F3397', 'L3_S29_F3400', 'L3_S29_F3403', 'L3_S29_F3406',\n",
       "       'L3_S29_F3409', 'L3_S29_F3411', 'L3_S29_F3414', 'L3_S29_F3416',\n",
       "       'L3_S29_F3418', 'L3_S29_F3420', 'L3_S29_F3423', 'L3_S29_F3426',\n",
       "       'L3_S29_F3429', 'L3_S29_F3432', 'L3_S29_F3435', 'L3_S29_F3438',\n",
       "       'L3_S29_F3441', 'L3_S29_F3444', 'L3_S29_F3446', 'L3_S29_F3448',\n",
       "       'L3_S29_F3451', 'L3_S29_F3454', 'L3_S29_F3457', 'L3_S29_F3460',\n",
       "       'L3_S29_F3463', 'L3_S29_F3466', 'L3_S29_F3469', 'L3_S29_F3472',\n",
       "       'L3_S29_F3475', 'L3_S29_F3478', 'L3_S29_F3481', 'L3_S29_F3484',\n",
       "       'L3_S29_F3487', 'L3_S29_F3490', 'L3_S29_F3493'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "important_features = freq['segment'][freq['segment'] > 0.60].index\n",
    "important_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "a85bd0cb-422b-4122-8f8c-c57abf754e85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(63,)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "important_features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "28f3e3f2-bd70-4d1e-8ef3-681415c57e77",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L3_S29_F3317</th>\n",
       "      <th>L3_S29_F3320</th>\n",
       "      <th>L3_S29_F3323</th>\n",
       "      <th>L3_S29_F3326</th>\n",
       "      <th>L3_S29_F3329</th>\n",
       "      <th>L3_S29_F3332</th>\n",
       "      <th>L3_S29_F3335</th>\n",
       "      <th>L3_S29_F3338</th>\n",
       "      <th>L3_S29_F3341</th>\n",
       "      <th>L3_S29_F3344</th>\n",
       "      <th>...</th>\n",
       "      <th>L3_S29_F3466</th>\n",
       "      <th>L3_S29_F3469</th>\n",
       "      <th>L3_S29_F3472</th>\n",
       "      <th>L3_S29_F3475</th>\n",
       "      <th>L3_S29_F3478</th>\n",
       "      <th>L3_S29_F3481</th>\n",
       "      <th>L3_S29_F3484</th>\n",
       "      <th>L3_S29_F3487</th>\n",
       "      <th>L3_S29_F3490</th>\n",
       "      <th>L3_S29_F3493</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>T1</td>\n",
       "      <td>T1</td>\n",
       "      <td>T1</td>\n",
       "      <td>T1</td>\n",
       "      <td>T1</td>\n",
       "      <td>T1</td>\n",
       "      <td>T1</td>\n",
       "      <td>T1</td>\n",
       "      <td>T1</td>\n",
       "      <td>T1</td>\n",
       "      <td>...</td>\n",
       "      <td>T1</td>\n",
       "      <td>T1</td>\n",
       "      <td>T1</td>\n",
       "      <td>T1</td>\n",
       "      <td>T1</td>\n",
       "      <td>T1</td>\n",
       "      <td>T1</td>\n",
       "      <td>T1</td>\n",
       "      <td>T1</td>\n",
       "      <td>T1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 63 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  L3_S29_F3317 L3_S29_F3320 L3_S29_F3323 L3_S29_F3326 L3_S29_F3329  \\\n",
       "0          NaN          NaN          NaN          NaN          NaN   \n",
       "1           T1           T1           T1           T1           T1   \n",
       "\n",
       "  L3_S29_F3332 L3_S29_F3335 L3_S29_F3338 L3_S29_F3341 L3_S29_F3344  ...  \\\n",
       "0          NaN          NaN          NaN          NaN          NaN  ...   \n",
       "1           T1           T1           T1           T1           T1  ...   \n",
       "\n",
       "  L3_S29_F3466 L3_S29_F3469 L3_S29_F3472 L3_S29_F3475 L3_S29_F3478  \\\n",
       "0          NaN          NaN          NaN          NaN          NaN   \n",
       "1           T1           T1           T1           T1           T1   \n",
       "\n",
       "  L3_S29_F3481 L3_S29_F3484 L3_S29_F3487 L3_S29_F3490 L3_S29_F3493  \n",
       "0          NaN          NaN          NaN          NaN          NaN  \n",
       "1           T1           T1           T1           T1           T1  \n",
       "\n",
       "[2 rows x 63 columns]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cat[important_features].agg(axis=0, func=pd.Series.unique)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ac55c0-6c87-48f2-b36e-2d4009758104",
   "metadata": {},
   "source": [
    "## Кодирование категориальных признаков"
   ]
  },
  {
   "attachments": {
    "64b91081-f1bd-4ad7-84ce-8c4db856e47e.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "f856ab14-2ff6-40e5-be86-452a51648c47",
   "metadata": {},
   "source": [
    "Значения категориальных переменных показывают принадлежность объекта к какой-либо группе, классу, а не величину, множество значений которой лежит на какой-либо числовой оси. Если не учесть эту особенность, то при построении модели алгоритм просто примет эти признаки за порядковые, что может повлиять на точность предсказаний.\n",
    "Наиболее распространенным способом перевода категориальных признаков в порядковые (без потери исходного смысла) является алгоритм  быстрого кодирования (One-Hot encoding). Его суть достаточно простая: категориальный столбец разбивается на n столбцов (n - количество категорий для данного признака). Каждый столбец соответствует своей категории. Для каждого объекта выборки выполняются следующие действия: в колонку относящуюся к категории объекта ставится единица, во все остальные – ноль. Например: у нас есть признак «цвет». Он может быть: белым, синим и красным, тогда для четырех объектов кодирование будет следующим.\n",
    "\n",
    "![image.png](attachment:64b91081-f1bd-4ad7-84ce-8c4db856e47e.png)\n",
    "\n",
    "Аналогичным образом закодируем категориальные признаки из нашего датасета. Получим матрицу X_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "5f3dc32e-7612-4504-a149-0ce8ab7dee9b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(200000, 126)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., ..., 1., 0., 1.],\n",
       "       [0., 1., 0., ..., 1., 0., 1.],\n",
       "       [1., 0., 1., ..., 0., 1., 0.],\n",
       "       ...,\n",
       "       [1., 0., 1., ..., 0., 1., 0.],\n",
       "       [1., 0., 1., ..., 0., 1., 0.],\n",
       "       [0., 1., 0., ..., 1., 0., 1.]])"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "one_hot_encoder = OneHotEncoder()\n",
    "X_categorical = one_hot_encoder.fit_transform(df_cat[important_features].to_numpy())\n",
    "print(X_categorical.shape)\n",
    "X_categorical = X_categorical.toarray()\n",
    "X_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "bd577ac8-cf80-43fd-b660-880718573ec4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = df_num['Response'].to_numpy()\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fedff163-150f-46cc-8569-ccfba5b55bc4",
   "metadata": {},
   "source": [
    "Для класса 0 найдем его \"типичный объект\". Для этого, для каждого столбца объектов этого класса определим значения, встречающиеся чаще всего. Эти знаяения и будут формировать признаки полученного объекта."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "d648a6ef-243d-40de-aaf6-da43440a8f1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "       0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
       "       1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "       0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
       "       1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "       0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0.,\n",
       "       1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1., 0., 1.,\n",
       "       0., 1., 0., 1., 0., 1., 0.])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base_for_zero = np.round(X_categorical[y == 0].sum(axis=0) / X_categorical.shape[0])\n",
    "base_for_zero"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9dab7f4d-b35f-459b-b9d7-b8e2c177bb88",
   "metadata": {},
   "source": [
    "Далее для каждого объекта в выборке вычислим расстояние Хемминга до \"типчного объекта класса 0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "08823200-4edd-4c21-a4f3-68049e0b00f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 0., ..., 0., 0., 1.])"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hamming_feature = np.apply_along_axis(lambda x: hamming(x, base_for_zero), axis=1, arr=X_categorical)\n",
    "hamming_feature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d7e6c90-856b-4ec7-b017-1669768ef4b3",
   "metadata": {},
   "source": [
    "Добавим новый признак в исходную матрицу"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "319b0f7c-02ce-4c85-ab8a-447d5dffa1d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., ..., 0., 1., 1.],\n",
       "       [0., 1., 0., ..., 0., 1., 1.],\n",
       "       [1., 0., 1., ..., 1., 0., 0.],\n",
       "       ...,\n",
       "       [1., 0., 1., ..., 1., 0., 0.],\n",
       "       [1., 0., 1., ..., 1., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 1., 1.]])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_categorical = np.concatenate((X_categorical, hamming_feature[...,np.newaxis]), axis=1)\n",
    "X_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "375f325e-a9fe-4d28-b813-a88afc2c9bc8",
   "metadata": {},
   "source": [
    "## Отбор числовых и категориальных признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "9c8688cd-484e-4d51-895c-a46e545288d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>L0_S0_F0</th>\n",
       "      <th>L0_S0_F2</th>\n",
       "      <th>L0_S0_F4</th>\n",
       "      <th>L0_S0_F6</th>\n",
       "      <th>L0_S0_F8</th>\n",
       "      <th>L0_S0_F10</th>\n",
       "      <th>L0_S0_F12</th>\n",
       "      <th>L0_S0_F14</th>\n",
       "      <th>L0_S0_F16</th>\n",
       "      <th>L0_S0_F18</th>\n",
       "      <th>...</th>\n",
       "      <th>L3_S50_F4245</th>\n",
       "      <th>L3_S50_F4247</th>\n",
       "      <th>L3_S50_F4249</th>\n",
       "      <th>L3_S50_F4251</th>\n",
       "      <th>L3_S50_F4253</th>\n",
       "      <th>L3_S51_F4256</th>\n",
       "      <th>L3_S51_F4258</th>\n",
       "      <th>L3_S51_F4260</th>\n",
       "      <th>L3_S51_F4262</th>\n",
       "      <th>Response</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.030</td>\n",
       "      <td>-0.034</td>\n",
       "      <td>-0.197</td>\n",
       "      <td>-0.179</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.116</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>-0.032</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.083</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.088</td>\n",
       "      <td>0.086</td>\n",
       "      <td>0.003</td>\n",
       "      <td>-0.052</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.025</td>\n",
       "      <td>-0.015</td>\n",
       "      <td>-0.072</td>\n",
       "      <td>-0.225</td>\n",
       "      <td>-0.147</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.036</td>\n",
       "      <td>-0.064</td>\n",
       "      <td>0.294</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.074</td>\n",
       "      <td>0.161</td>\n",
       "      <td>0.022</td>\n",
       "      <td>0.128</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>-0.046</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.055</td>\n",
       "      <td>-0.086</td>\n",
       "      <td>0.294</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.118</td>\n",
       "      <td>0.025</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.168</td>\n",
       "      <td>-0.169</td>\n",
       "      <td>-0.099</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>0.036</td>\n",
       "      <td>0.056</td>\n",
       "      <td>0.330</td>\n",
       "      <td>0.330</td>\n",
       "      <td>-0.056</td>\n",
       "      <td>0.116</td>\n",
       "      <td>0.015</td>\n",
       "      <td>0.048</td>\n",
       "      <td>-0.010</td>\n",
       "      <td>-0.099</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>-0.055</td>\n",
       "      <td>-0.056</td>\n",
       "      <td>-0.179</td>\n",
       "      <td>-0.161</td>\n",
       "      <td>-0.056</td>\n",
       "      <td>0.070</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.008</td>\n",
       "      <td>-0.026</td>\n",
       "      <td>0.013</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows × 969 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        L0_S0_F0  L0_S0_F2  L0_S0_F4  L0_S0_F6  L0_S0_F8  L0_S0_F10  \\\n",
       "0          0.030    -0.034    -0.197    -0.179     0.118      0.116   \n",
       "1            NaN       NaN       NaN       NaN       NaN        NaN   \n",
       "2          0.088     0.086     0.003    -0.052     0.161      0.025   \n",
       "3         -0.036    -0.064     0.294     0.330     0.074      0.161   \n",
       "4         -0.055    -0.086     0.294     0.330     0.118      0.025   \n",
       "...          ...       ...       ...       ...       ...        ...   \n",
       "199995       NaN       NaN       NaN       NaN       NaN        NaN   \n",
       "199996       NaN       NaN       NaN       NaN       NaN        NaN   \n",
       "199997     0.036     0.056     0.330     0.330    -0.056      0.116   \n",
       "199998    -0.055    -0.056    -0.179    -0.161    -0.056      0.070   \n",
       "199999       NaN       NaN       NaN       NaN       NaN        NaN   \n",
       "\n",
       "        L0_S0_F12  L0_S0_F14  L0_S0_F16  L0_S0_F18  ...  L3_S50_F4245  \\\n",
       "0          -0.015     -0.032      0.020      0.083  ...           NaN   \n",
       "1             NaN        NaN        NaN        NaN  ...           NaN   \n",
       "2          -0.015     -0.072     -0.225     -0.147  ...           NaN   \n",
       "3           0.022      0.128     -0.026     -0.046  ...           NaN   \n",
       "4           0.030      0.168     -0.169     -0.099  ...           NaN   \n",
       "...           ...        ...        ...        ...  ...           ...   \n",
       "199995        NaN        NaN        NaN        NaN  ...           0.0   \n",
       "199996        NaN        NaN        NaN        NaN  ...           NaN   \n",
       "199997      0.015      0.048     -0.010     -0.099  ...           NaN   \n",
       "199998      0.000      0.008     -0.026      0.013  ...           NaN   \n",
       "199999        NaN        NaN        NaN        NaN  ...           NaN   \n",
       "\n",
       "        L3_S50_F4247  L3_S50_F4249  L3_S50_F4251  L3_S50_F4253  L3_S51_F4256  \\\n",
       "0                NaN           NaN           NaN           NaN           NaN   \n",
       "1                NaN           NaN           NaN           NaN           NaN   \n",
       "2                NaN           NaN           NaN           NaN           NaN   \n",
       "3                NaN           NaN           NaN           NaN           NaN   \n",
       "4                NaN           NaN           NaN           NaN           NaN   \n",
       "...              ...           ...           ...           ...           ...   \n",
       "199995           0.0           0.0           0.0         -0.25           0.0   \n",
       "199996           NaN           NaN           NaN           NaN           NaN   \n",
       "199997           NaN           NaN           NaN           NaN           NaN   \n",
       "199998           NaN           NaN           NaN           NaN           NaN   \n",
       "199999           NaN           NaN           NaN           NaN           NaN   \n",
       "\n",
       "        L3_S51_F4258  L3_S51_F4260  L3_S51_F4262  Response  \n",
       "0                NaN           NaN           NaN       0.0  \n",
       "1                NaN           NaN           NaN       0.0  \n",
       "2                NaN           NaN           NaN       0.0  \n",
       "3                NaN           NaN           NaN       0.0  \n",
       "4                NaN           NaN           NaN       0.0  \n",
       "...              ...           ...           ...       ...  \n",
       "199995           0.0           0.0           0.0       0.0  \n",
       "199996           NaN           NaN           NaN       0.0  \n",
       "199997           NaN           NaN           NaN       0.0  \n",
       "199998           NaN           NaN           NaN       0.0  \n",
       "199999           NaN           NaN           NaN       0.0  \n",
       "\n",
       "[200000 rows x 969 columns]"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_num"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0e8075e-19b6-4637-a8b7-cd07667c4cd3",
   "metadata": {},
   "source": [
    "Извлечем порядковые (числовые) признаки (столбцы) из датафрейма df_num в массив numpy - X_numeric. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "f8d72dc3-0eb7-4797-bce3-c76945520588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.03 , -0.034, -0.197, ...,    nan,    nan,    nan],\n",
       "       [   nan,    nan,    nan, ...,    nan,    nan,    nan],\n",
       "       [ 0.088,  0.086,  0.003, ...,    nan,    nan,    nan],\n",
       "       ...,\n",
       "       [ 0.036,  0.056,  0.33 , ...,    nan,    nan,    nan],\n",
       "       [-0.055, -0.056, -0.179, ...,    nan,    nan,    nan],\n",
       "       [   nan,    nan,    nan, ...,    nan,    nan,    nan]])"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_numeric = df_num.drop(columns='Response').to_numpy()\n",
    "X_numeric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "985b3d58-6247-4f15-8971-a171ab8eb098",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 968)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_numeric.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baca11e3-d359-4f71-a88b-d38fa0bca1eb",
   "metadata": {},
   "source": [
    "Теперь объединим полученные матрицы X_numeric и X_categorical в одну матрицу признаков X. Просто разместим столбцы матриц рядом друг с другом."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "30113662-1b5b-4b83-9571-74ec36b4124c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.03 , -0.034, -0.197, ...,  0.   ,  1.   ,  1.   ],\n",
       "       [   nan,    nan,    nan, ...,  0.   ,  1.   ,  1.   ],\n",
       "       [ 0.088,  0.086,  0.003, ...,  1.   ,  0.   ,  0.   ],\n",
       "       ...,\n",
       "       [ 0.036,  0.056,  0.33 , ...,  1.   ,  0.   ,  0.   ],\n",
       "       [-0.055, -0.056, -0.179, ...,  1.   ,  0.   ,  0.   ],\n",
       "       [   nan,    nan,    nan, ...,  0.   ,  1.   ,  1.   ]])"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.concatenate((X_numeric, X_categorical), axis=1)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64e09b09-4acd-4fa5-89ac-c98e195dda3a",
   "metadata": {},
   "source": [
    "Есть множество способов оценить значимость признака. В данной работе мы будем использовать алгоритм градиентного бустинга из библиотеки xgboost. Обучим модель. При этом для нас несильно важно качество предсказаний полученной модели, так как мы используем ее только для отбора наиболее значимых признаков.  Подробнее этот алгоритм рассмотрен в следующих разделах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "3449d33d-1f46-4c0f-9462-93580f64904d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:55:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.00371853, 0.0025491 , 0.00308008, ..., 0.        , 0.        ,\n",
       "       0.        ], dtype=float32)"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model = XGBClassifier(\n",
    "            tree_method=\"gpu_hist\",\n",
    "            enable_categorical=True,\n",
    "            use_label_encoder=False,\n",
    "        )\n",
    "\n",
    "\n",
    "model.fit(X, y)\n",
    "f_importance = model.feature_importances_\n",
    "f_importance"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0a9df7-3966-404a-89db-22f9d504cb40",
   "metadata": {},
   "source": [
    "У градиентного бустинга есть замечательное свойство – он способен определять важность признаков. Это возможно благодаря алгоритму MDI (mean decrease in impurity), который вычисляет важность объекта на основе усредненного значения доли объектов, которые он разделил на первом уровне каждого решающего дерева.\n",
    "\n",
    "Полученные оценки разобьем на два массива: один соответствует категориальными признакам (categorical_f) другой порядковым (numeric_f). Далее для каждого массива построим «ящики с усами»."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "a6b2d512-dbd0-4acf-9703-eae16dd1c25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_f = f_importance[:968]\n",
    "categorical_f = f_importance[968:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "a0184894-96b0-459d-a4bd-a348e9ba44ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Разброс категориальных признаков по релевантности')"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "fig, axes = plt.subplots(1, 2, sharex=True, sharey=True)\n",
    "fig.set_figheight(5)\n",
    "fig.set_figwidth(14)\n",
    "axes[0].boxplot(numeric_f)\n",
    "axes[0].grid()\n",
    "axes[0].set_title('Разброс числовых признаков по релевантности')\n",
    "\n",
    "axes[1].boxplot(categorical_f)\n",
    "axes[1].grid()\n",
    "axes[1].set_title('Разброс категориальных признаков по релевантности')\n",
    "#plt.title('Разброс признаков по релевантности')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61733920-8dc8-432f-9420-dc8679396925",
   "metadata": {},
   "source": [
    "Видно, что числовые признаки можно условно разделить на две части: те что лежат ниже значения 0.005 (эти признаки мы будем считать незначимыми) и те которые лежат выше 0.005 (их мы будем считать значимыми). Если сравнить порядковые признаки с категориальными, то последние лежат во много раз ниже выбранного нами порога в 0.005. Поэтому при построении модели категориальные признаки использоваться не будут, как минимум – при построении моделей основанных на решающих деревьях.\n",
    "\n",
    "Применим порог 0.005 для отделения значимых признаков и по их индексам определим названия столбцов в датафрейме. Получим 9 наиболее значимых признаков и поместим их названия в chosen_features. По этим признакам будет строится модель."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "14fde03a-902f-496b-899e-197d925343fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([849, 862, 848, 360, 866, 164, 937, 105,  73], dtype=int64)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_features = numeric_f.argsort()[::-1][:9]\n",
    "m_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "6985b33d-2582-4040-b024-abf326864290",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01503585, 0.01482963, 0.00930516, 0.00766288, 0.00709718,\n",
       "       0.00593049, 0.00581373, 0.0057841 , 0.00528963], dtype=float32)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numeric_f[m_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58797264-1304-4b1e-8275-279f0e8412ca",
   "metadata": {},
   "source": [
    "## Работа с времянными признаками\n",
    "Теперь изучим таблицу с временными данными"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "f9d59c65-1f9c-43eb-a239-cbd2b7ac68d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>L0_S0_D1</th>\n",
       "      <th>L0_S0_D3</th>\n",
       "      <th>L0_S0_D5</th>\n",
       "      <th>L0_S0_D7</th>\n",
       "      <th>L0_S0_D9</th>\n",
       "      <th>L0_S0_D11</th>\n",
       "      <th>L0_S0_D13</th>\n",
       "      <th>L0_S0_D15</th>\n",
       "      <th>L0_S0_D17</th>\n",
       "      <th>...</th>\n",
       "      <th>L3_S50_D4246</th>\n",
       "      <th>L3_S50_D4248</th>\n",
       "      <th>L3_S50_D4250</th>\n",
       "      <th>L3_S50_D4252</th>\n",
       "      <th>L3_S50_D4254</th>\n",
       "      <th>L3_S51_D4255</th>\n",
       "      <th>L3_S51_D4257</th>\n",
       "      <th>L3_S51_D4259</th>\n",
       "      <th>L3_S51_D4261</th>\n",
       "      <th>L3_S51_D4263</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4.0</td>\n",
       "      <td>82.24</td>\n",
       "      <td>82.24</td>\n",
       "      <td>82.24</td>\n",
       "      <td>82.24</td>\n",
       "      <td>82.24</td>\n",
       "      <td>82.24</td>\n",
       "      <td>82.24</td>\n",
       "      <td>82.24</td>\n",
       "      <td>82.24</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.0</td>\n",
       "      <td>1618.70</td>\n",
       "      <td>1618.70</td>\n",
       "      <td>1618.70</td>\n",
       "      <td>1618.70</td>\n",
       "      <td>1618.70</td>\n",
       "      <td>1618.70</td>\n",
       "      <td>1618.70</td>\n",
       "      <td>1618.70</td>\n",
       "      <td>1618.70</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.0</td>\n",
       "      <td>1149.20</td>\n",
       "      <td>1149.20</td>\n",
       "      <td>1149.20</td>\n",
       "      <td>1149.20</td>\n",
       "      <td>1149.20</td>\n",
       "      <td>1149.20</td>\n",
       "      <td>1149.20</td>\n",
       "      <td>1149.20</td>\n",
       "      <td>1149.20</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11.0</td>\n",
       "      <td>602.64</td>\n",
       "      <td>602.64</td>\n",
       "      <td>602.64</td>\n",
       "      <td>602.64</td>\n",
       "      <td>602.64</td>\n",
       "      <td>602.64</td>\n",
       "      <td>602.64</td>\n",
       "      <td>602.64</td>\n",
       "      <td>602.64</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>399894.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>724.88</td>\n",
       "      <td>724.88</td>\n",
       "      <td>724.88</td>\n",
       "      <td>724.88</td>\n",
       "      <td>724.88</td>\n",
       "      <td>724.89</td>\n",
       "      <td>724.89</td>\n",
       "      <td>724.89</td>\n",
       "      <td>724.89</td>\n",
       "      <td>724.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>399896.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>399897.0</td>\n",
       "      <td>675.79</td>\n",
       "      <td>675.79</td>\n",
       "      <td>675.79</td>\n",
       "      <td>675.79</td>\n",
       "      <td>675.79</td>\n",
       "      <td>675.79</td>\n",
       "      <td>675.79</td>\n",
       "      <td>675.79</td>\n",
       "      <td>675.79</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>399898.0</td>\n",
       "      <td>1225.57</td>\n",
       "      <td>1225.57</td>\n",
       "      <td>1225.57</td>\n",
       "      <td>1225.57</td>\n",
       "      <td>1225.57</td>\n",
       "      <td>1225.57</td>\n",
       "      <td>1225.57</td>\n",
       "      <td>1225.57</td>\n",
       "      <td>1225.57</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>399899.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows × 1157 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Id  L0_S0_D1  L0_S0_D3  L0_S0_D5  L0_S0_D7  L0_S0_D9  L0_S0_D11  \\\n",
       "0            4.0     82.24     82.24     82.24     82.24     82.24      82.24   \n",
       "1            6.0       NaN       NaN       NaN       NaN       NaN        NaN   \n",
       "2            7.0   1618.70   1618.70   1618.70   1618.70   1618.70    1618.70   \n",
       "3            9.0   1149.20   1149.20   1149.20   1149.20   1149.20    1149.20   \n",
       "4           11.0    602.64    602.64    602.64    602.64    602.64     602.64   \n",
       "...          ...       ...       ...       ...       ...       ...        ...   \n",
       "199995  399894.0       NaN       NaN       NaN       NaN       NaN        NaN   \n",
       "199996  399896.0       NaN       NaN       NaN       NaN       NaN        NaN   \n",
       "199997  399897.0    675.79    675.79    675.79    675.79    675.79     675.79   \n",
       "199998  399898.0   1225.57   1225.57   1225.57   1225.57   1225.57    1225.57   \n",
       "199999  399899.0       NaN       NaN       NaN       NaN       NaN        NaN   \n",
       "\n",
       "        L0_S0_D13  L0_S0_D15  L0_S0_D17  ...  L3_S50_D4246  L3_S50_D4248  \\\n",
       "0           82.24      82.24      82.24  ...           NaN           NaN   \n",
       "1             NaN        NaN        NaN  ...           NaN           NaN   \n",
       "2         1618.70    1618.70    1618.70  ...           NaN           NaN   \n",
       "3         1149.20    1149.20    1149.20  ...           NaN           NaN   \n",
       "4          602.64     602.64     602.64  ...           NaN           NaN   \n",
       "...           ...        ...        ...  ...           ...           ...   \n",
       "199995        NaN        NaN        NaN  ...        724.88        724.88   \n",
       "199996        NaN        NaN        NaN  ...           NaN           NaN   \n",
       "199997     675.79     675.79     675.79  ...           NaN           NaN   \n",
       "199998    1225.57    1225.57    1225.57  ...           NaN           NaN   \n",
       "199999        NaN        NaN        NaN  ...           NaN           NaN   \n",
       "\n",
       "        L3_S50_D4250  L3_S50_D4252  L3_S50_D4254  L3_S51_D4255  L3_S51_D4257  \\\n",
       "0                NaN           NaN           NaN           NaN           NaN   \n",
       "1                NaN           NaN           NaN           NaN           NaN   \n",
       "2                NaN           NaN           NaN           NaN           NaN   \n",
       "3                NaN           NaN           NaN           NaN           NaN   \n",
       "4                NaN           NaN           NaN           NaN           NaN   \n",
       "...              ...           ...           ...           ...           ...   \n",
       "199995        724.88        724.88        724.88        724.89        724.89   \n",
       "199996           NaN           NaN           NaN           NaN           NaN   \n",
       "199997           NaN           NaN           NaN           NaN           NaN   \n",
       "199998           NaN           NaN           NaN           NaN           NaN   \n",
       "199999           NaN           NaN           NaN           NaN           NaN   \n",
       "\n",
       "        L3_S51_D4259  L3_S51_D4261  L3_S51_D4263  \n",
       "0                NaN           NaN           NaN  \n",
       "1                NaN           NaN           NaN  \n",
       "2                NaN           NaN           NaN  \n",
       "3                NaN           NaN           NaN  \n",
       "4                NaN           NaN           NaN  \n",
       "...              ...           ...           ...  \n",
       "199995        724.89        724.89        724.89  \n",
       "199996           NaN           NaN           NaN  \n",
       "199997           NaN           NaN           NaN  \n",
       "199998           NaN           NaN           NaN  \n",
       "199999           NaN           NaN           NaN  \n",
       "\n",
       "[200000 rows x 1157 columns]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dat = pd.read_csv('datasets/train_date.csv', sep=',', nrows=200000, dtype='float64')\n",
    "df_dat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "7026f723-ca25-49aa-ab6a-260ac99a978b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>L0_S0_D1</th>\n",
       "      <th>L0_S0_D3</th>\n",
       "      <th>L0_S0_D5</th>\n",
       "      <th>L0_S0_D7</th>\n",
       "      <th>L0_S0_D9</th>\n",
       "      <th>L0_S0_D11</th>\n",
       "      <th>L0_S0_D13</th>\n",
       "      <th>L0_S0_D15</th>\n",
       "      <th>L0_S0_D17</th>\n",
       "      <th>...</th>\n",
       "      <th>L3_S50_D4246</th>\n",
       "      <th>L3_S50_D4248</th>\n",
       "      <th>L3_S50_D4250</th>\n",
       "      <th>L3_S50_D4252</th>\n",
       "      <th>L3_S50_D4254</th>\n",
       "      <th>L3_S51_D4255</th>\n",
       "      <th>L3_S51_D4257</th>\n",
       "      <th>L3_S51_D4259</th>\n",
       "      <th>L3_S51_D4261</th>\n",
       "      <th>L3_S51_D4263</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>200000.000000</td>\n",
       "      <td>115932.000000</td>\n",
       "      <td>115932.000000</td>\n",
       "      <td>115932.000000</td>\n",
       "      <td>115932.000000</td>\n",
       "      <td>115932.000000</td>\n",
       "      <td>115932.000000</td>\n",
       "      <td>115932.000000</td>\n",
       "      <td>115932.000000</td>\n",
       "      <td>115932.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>5316.000000</td>\n",
       "      <td>5316.000000</td>\n",
       "      <td>5316.000000</td>\n",
       "      <td>5316.000000</td>\n",
       "      <td>5316.000000</td>\n",
       "      <td>10383.000000</td>\n",
       "      <td>10383.000000</td>\n",
       "      <td>10383.000000</td>\n",
       "      <td>10383.000000</td>\n",
       "      <td>10383.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>200029.947135</td>\n",
       "      <td>872.728727</td>\n",
       "      <td>872.728727</td>\n",
       "      <td>872.728727</td>\n",
       "      <td>872.728727</td>\n",
       "      <td>872.728727</td>\n",
       "      <td>872.728727</td>\n",
       "      <td>872.728727</td>\n",
       "      <td>872.728727</td>\n",
       "      <td>872.728727</td>\n",
       "      <td>...</td>\n",
       "      <td>1026.901055</td>\n",
       "      <td>1026.901055</td>\n",
       "      <td>1026.901055</td>\n",
       "      <td>1026.901055</td>\n",
       "      <td>1026.901055</td>\n",
       "      <td>1029.697533</td>\n",
       "      <td>1029.697533</td>\n",
       "      <td>1029.697533</td>\n",
       "      <td>1029.697533</td>\n",
       "      <td>1029.697533</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>115402.589920</td>\n",
       "      <td>503.473668</td>\n",
       "      <td>503.473668</td>\n",
       "      <td>503.473668</td>\n",
       "      <td>503.473668</td>\n",
       "      <td>503.473668</td>\n",
       "      <td>503.473668</td>\n",
       "      <td>503.473668</td>\n",
       "      <td>503.473668</td>\n",
       "      <td>503.473668</td>\n",
       "      <td>...</td>\n",
       "      <td>427.886773</td>\n",
       "      <td>427.886773</td>\n",
       "      <td>427.886773</td>\n",
       "      <td>427.886773</td>\n",
       "      <td>427.886773</td>\n",
       "      <td>430.562826</td>\n",
       "      <td>430.562826</td>\n",
       "      <td>430.562826</td>\n",
       "      <td>430.562826</td>\n",
       "      <td>430.562826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.320000</td>\n",
       "      <td>1.320000</td>\n",
       "      <td>1.320000</td>\n",
       "      <td>1.320000</td>\n",
       "      <td>1.320000</td>\n",
       "      <td>1.380000</td>\n",
       "      <td>1.380000</td>\n",
       "      <td>1.380000</td>\n",
       "      <td>1.380000</td>\n",
       "      <td>1.380000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>100148.500000</td>\n",
       "      <td>392.410000</td>\n",
       "      <td>392.410000</td>\n",
       "      <td>392.410000</td>\n",
       "      <td>392.410000</td>\n",
       "      <td>392.410000</td>\n",
       "      <td>392.410000</td>\n",
       "      <td>392.410000</td>\n",
       "      <td>392.410000</td>\n",
       "      <td>392.410000</td>\n",
       "      <td>...</td>\n",
       "      <td>558.090000</td>\n",
       "      <td>558.090000</td>\n",
       "      <td>558.090000</td>\n",
       "      <td>558.090000</td>\n",
       "      <td>558.090000</td>\n",
       "      <td>558.060000</td>\n",
       "      <td>558.060000</td>\n",
       "      <td>558.060000</td>\n",
       "      <td>558.060000</td>\n",
       "      <td>558.060000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>200353.000000</td>\n",
       "      <td>904.010000</td>\n",
       "      <td>904.010000</td>\n",
       "      <td>904.010000</td>\n",
       "      <td>904.010000</td>\n",
       "      <td>904.010000</td>\n",
       "      <td>904.010000</td>\n",
       "      <td>904.010000</td>\n",
       "      <td>904.010000</td>\n",
       "      <td>904.010000</td>\n",
       "      <td>...</td>\n",
       "      <td>1225.210000</td>\n",
       "      <td>1225.210000</td>\n",
       "      <td>1225.210000</td>\n",
       "      <td>1225.210000</td>\n",
       "      <td>1225.210000</td>\n",
       "      <td>1225.290000</td>\n",
       "      <td>1225.290000</td>\n",
       "      <td>1225.290000</td>\n",
       "      <td>1225.290000</td>\n",
       "      <td>1225.290000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>299819.500000</td>\n",
       "      <td>1364.270000</td>\n",
       "      <td>1364.270000</td>\n",
       "      <td>1364.270000</td>\n",
       "      <td>1364.270000</td>\n",
       "      <td>1364.270000</td>\n",
       "      <td>1364.270000</td>\n",
       "      <td>1364.270000</td>\n",
       "      <td>1364.270000</td>\n",
       "      <td>1364.270000</td>\n",
       "      <td>...</td>\n",
       "      <td>1408.320000</td>\n",
       "      <td>1408.320000</td>\n",
       "      <td>1408.320000</td>\n",
       "      <td>1408.320000</td>\n",
       "      <td>1408.320000</td>\n",
       "      <td>1408.500000</td>\n",
       "      <td>1408.500000</td>\n",
       "      <td>1408.500000</td>\n",
       "      <td>1408.500000</td>\n",
       "      <td>1408.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>399899.000000</td>\n",
       "      <td>1713.710000</td>\n",
       "      <td>1713.710000</td>\n",
       "      <td>1713.710000</td>\n",
       "      <td>1713.710000</td>\n",
       "      <td>1713.710000</td>\n",
       "      <td>1713.710000</td>\n",
       "      <td>1713.710000</td>\n",
       "      <td>1713.710000</td>\n",
       "      <td>1713.710000</td>\n",
       "      <td>...</td>\n",
       "      <td>1457.500000</td>\n",
       "      <td>1457.500000</td>\n",
       "      <td>1457.500000</td>\n",
       "      <td>1457.500000</td>\n",
       "      <td>1457.500000</td>\n",
       "      <td>1457.500000</td>\n",
       "      <td>1457.500000</td>\n",
       "      <td>1457.500000</td>\n",
       "      <td>1457.500000</td>\n",
       "      <td>1457.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 1157 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Id       L0_S0_D1       L0_S0_D3       L0_S0_D5  \\\n",
       "count  200000.000000  115932.000000  115932.000000  115932.000000   \n",
       "mean   200029.947135     872.728727     872.728727     872.728727   \n",
       "std    115402.589920     503.473668     503.473668     503.473668   \n",
       "min         4.000000       0.010000       0.010000       0.010000   \n",
       "25%    100148.500000     392.410000     392.410000     392.410000   \n",
       "50%    200353.000000     904.010000     904.010000     904.010000   \n",
       "75%    299819.500000    1364.270000    1364.270000    1364.270000   \n",
       "max    399899.000000    1713.710000    1713.710000    1713.710000   \n",
       "\n",
       "            L0_S0_D7       L0_S0_D9      L0_S0_D11      L0_S0_D13  \\\n",
       "count  115932.000000  115932.000000  115932.000000  115932.000000   \n",
       "mean      872.728727     872.728727     872.728727     872.728727   \n",
       "std       503.473668     503.473668     503.473668     503.473668   \n",
       "min         0.010000       0.010000       0.010000       0.010000   \n",
       "25%       392.410000     392.410000     392.410000     392.410000   \n",
       "50%       904.010000     904.010000     904.010000     904.010000   \n",
       "75%      1364.270000    1364.270000    1364.270000    1364.270000   \n",
       "max      1713.710000    1713.710000    1713.710000    1713.710000   \n",
       "\n",
       "           L0_S0_D15      L0_S0_D17  ...  L3_S50_D4246  L3_S50_D4248  \\\n",
       "count  115932.000000  115932.000000  ...   5316.000000   5316.000000   \n",
       "mean      872.728727     872.728727  ...   1026.901055   1026.901055   \n",
       "std       503.473668     503.473668  ...    427.886773    427.886773   \n",
       "min         0.010000       0.010000  ...      1.320000      1.320000   \n",
       "25%       392.410000     392.410000  ...    558.090000    558.090000   \n",
       "50%       904.010000     904.010000  ...   1225.210000   1225.210000   \n",
       "75%      1364.270000    1364.270000  ...   1408.320000   1408.320000   \n",
       "max      1713.710000    1713.710000  ...   1457.500000   1457.500000   \n",
       "\n",
       "       L3_S50_D4250  L3_S50_D4252  L3_S50_D4254  L3_S51_D4255  L3_S51_D4257  \\\n",
       "count   5316.000000   5316.000000   5316.000000  10383.000000  10383.000000   \n",
       "mean    1026.901055   1026.901055   1026.901055   1029.697533   1029.697533   \n",
       "std      427.886773    427.886773    427.886773    430.562826    430.562826   \n",
       "min        1.320000      1.320000      1.320000      1.380000      1.380000   \n",
       "25%      558.090000    558.090000    558.090000    558.060000    558.060000   \n",
       "50%     1225.210000   1225.210000   1225.210000   1225.290000   1225.290000   \n",
       "75%     1408.320000   1408.320000   1408.320000   1408.500000   1408.500000   \n",
       "max     1457.500000   1457.500000   1457.500000   1457.500000   1457.500000   \n",
       "\n",
       "       L3_S51_D4259  L3_S51_D4261  L3_S51_D4263  \n",
       "count  10383.000000  10383.000000  10383.000000  \n",
       "mean    1029.697533   1029.697533   1029.697533  \n",
       "std      430.562826    430.562826    430.562826  \n",
       "min        1.380000      1.380000      1.380000  \n",
       "25%      558.060000    558.060000    558.060000  \n",
       "50%     1225.290000   1225.290000   1225.290000  \n",
       "75%     1408.500000   1408.500000   1408.500000  \n",
       "max     1457.500000   1457.500000   1457.500000  \n",
       "\n",
       "[8 rows x 1157 columns]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dat.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ee076b-8fb9-4604-8890-337ff308b67f",
   "metadata": {},
   "source": [
    "Подсчитаем количество ячеек без пропусков для каждого столбца. Мы также удалим столбец Id (через метод drop), после этого обновим индексы методом reset_index. При этом исходные индексы просто перенесутся в новый соседний столбец index, вычисленные до этого значения частот останутся в столбце 0. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "00c9598e-c3c5-43a4-8f76-015aa5c49a50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "L0_S0_D1        115932\n",
       "L0_S0_D3        115932\n",
       "L0_S0_D5        115932\n",
       "L0_S0_D7        115932\n",
       "L0_S0_D9        115932\n",
       "                 ...  \n",
       "L3_S51_D4255     10383\n",
       "L3_S51_D4257     10383\n",
       "L3_S51_D4259     10383\n",
       "L3_S51_D4261     10383\n",
       "L3_S51_D4263     10383\n",
       "Length: 1156, dtype: int64"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_not_null = df_dat.count(axis=0).drop('Id')\n",
    "count_not_null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "fbd61915-d3ec-4688-9094-cd34c7e7adc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L0_S0_D1</td>\n",
       "      <td>115932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L0_S0_D3</td>\n",
       "      <td>115932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>L0_S0_D5</td>\n",
       "      <td>115932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>L0_S0_D7</td>\n",
       "      <td>115932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L0_S0_D9</td>\n",
       "      <td>115932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1151</th>\n",
       "      <td>L3_S51_D4255</td>\n",
       "      <td>10383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1152</th>\n",
       "      <td>L3_S51_D4257</td>\n",
       "      <td>10383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1153</th>\n",
       "      <td>L3_S51_D4259</td>\n",
       "      <td>10383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1154</th>\n",
       "      <td>L3_S51_D4261</td>\n",
       "      <td>10383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1155</th>\n",
       "      <td>L3_S51_D4263</td>\n",
       "      <td>10383</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1156 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             index       0\n",
       "0         L0_S0_D1  115932\n",
       "1         L0_S0_D3  115932\n",
       "2         L0_S0_D5  115932\n",
       "3         L0_S0_D7  115932\n",
       "4         L0_S0_D9  115932\n",
       "...            ...     ...\n",
       "1151  L3_S51_D4255   10383\n",
       "1152  L3_S51_D4257   10383\n",
       "1153  L3_S51_D4259   10383\n",
       "1154  L3_S51_D4261   10383\n",
       "1155  L3_S51_D4263   10383\n",
       "\n",
       "[1156 rows x 2 columns]"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_not_null = count_not_null.reset_index()\n",
    "count_not_null"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04d28bf4-14af-4f58-874e-851e606599e9",
   "metadata": {},
   "source": [
    "Изменим названия колонок (столбец index). Оставим только название станций, на которых происходили измерения (исходную колонку просто перенесем в столбец feature). После этого удалим дубликаты названий методом drop_dublicates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "c953ea6b-75f4-4b64-a38d-d3cc2e95acdf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1054</th>\n",
       "      <td>S37</td>\n",
       "      <td>188967</td>\n",
       "      <td>L3_S37_D3949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1053</th>\n",
       "      <td>S37</td>\n",
       "      <td>188967</td>\n",
       "      <td>L3_S37_D3947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1052</th>\n",
       "      <td>S37</td>\n",
       "      <td>188967</td>\n",
       "      <td>L3_S37_D3945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1051</th>\n",
       "      <td>S37</td>\n",
       "      <td>188967</td>\n",
       "      <td>L3_S37_D3943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1050</th>\n",
       "      <td>S37</td>\n",
       "      <td>188967</td>\n",
       "      <td>L3_S37_D3942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1096</th>\n",
       "      <td>S42</td>\n",
       "      <td>1</td>\n",
       "      <td>L3_S42_D4057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1094</th>\n",
       "      <td>S42</td>\n",
       "      <td>1</td>\n",
       "      <td>L3_S42_D4049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1095</th>\n",
       "      <td>S42</td>\n",
       "      <td>1</td>\n",
       "      <td>L3_S42_D4053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1118</th>\n",
       "      <td>S46</td>\n",
       "      <td>0</td>\n",
       "      <td>L3_S46_D4135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>S24</td>\n",
       "      <td>0</td>\n",
       "      <td>L1_S24_D1158</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1156 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     index       0       feature\n",
       "1054   S37  188967  L3_S37_D3949\n",
       "1053   S37  188967  L3_S37_D3947\n",
       "1052   S37  188967  L3_S37_D3945\n",
       "1051   S37  188967  L3_S37_D3943\n",
       "1050   S37  188967  L3_S37_D3942\n",
       "...    ...     ...           ...\n",
       "1096   S42       1  L3_S42_D4057\n",
       "1094   S42       1  L3_S42_D4049\n",
       "1095   S42       1  L3_S42_D4053\n",
       "1118   S46       0  L3_S46_D4135\n",
       "302    S24       0  L1_S24_D1158\n",
       "\n",
       "[1156 rows x 3 columns]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_not_null.sort_values(by=0, inplace=True, ascending=False)\n",
    "count_not_null['feature'] = count_not_null['index']\n",
    "count_not_null['index'] = count_not_null['index'].str.split('_', expand=True)[1]\n",
    "count_not_null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "86d55e13-8aa1-4485-b2e5-1abbf0a04ee5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1054</th>\n",
       "      <td>S37</td>\n",
       "      <td>188967</td>\n",
       "      <td>L3_S37_D3949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1003</th>\n",
       "      <td>S30</td>\n",
       "      <td>188856</td>\n",
       "      <td>L3_S30_D3781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>906</th>\n",
       "      <td>S29</td>\n",
       "      <td>188815</td>\n",
       "      <td>L3_S29_D3383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1033</th>\n",
       "      <td>S34</td>\n",
       "      <td>188009</td>\n",
       "      <td>L3_S34_D3883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1020</th>\n",
       "      <td>S33</td>\n",
       "      <td>187953</td>\n",
       "      <td>L3_S33_D3858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>S1</td>\n",
       "      <td>115960</td>\n",
       "      <td>L0_S1_D26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>S8</td>\n",
       "      <td>115937</td>\n",
       "      <td>L0_S8_D150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>S0</td>\n",
       "      <td>115932</td>\n",
       "      <td>L0_S0_D3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044</th>\n",
       "      <td>S36</td>\n",
       "      <td>96117</td>\n",
       "      <td>L3_S36_D3923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1039</th>\n",
       "      <td>S35</td>\n",
       "      <td>92968</td>\n",
       "      <td>L3_S35_D3905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>S5</td>\n",
       "      <td>58441</td>\n",
       "      <td>L0_S5_D115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>S6</td>\n",
       "      <td>58434</td>\n",
       "      <td>L0_S6_D124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>S2</td>\n",
       "      <td>58378</td>\n",
       "      <td>L0_S2_D58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>S4</td>\n",
       "      <td>57667</td>\n",
       "      <td>L0_S4_D106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>S3</td>\n",
       "      <td>57663</td>\n",
       "      <td>L0_S3_D82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>S7</td>\n",
       "      <td>57654</td>\n",
       "      <td>L0_S7_D137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>S20</td>\n",
       "      <td>40018</td>\n",
       "      <td>L0_S20_D467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>S13</td>\n",
       "      <td>40011</td>\n",
       "      <td>L0_S13_D357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>S12</td>\n",
       "      <td>40007</td>\n",
       "      <td>L0_S12_D337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>S9</td>\n",
       "      <td>38879</td>\n",
       "      <td>L0_S9_D167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>S11</td>\n",
       "      <td>38793</td>\n",
       "      <td>L0_S11_D280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>S10</td>\n",
       "      <td>38622</td>\n",
       "      <td>L0_S10_D236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>815</th>\n",
       "      <td>S26</td>\n",
       "      <td>36772</td>\n",
       "      <td>L2_S26_D3074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>S24</td>\n",
       "      <td>22093</td>\n",
       "      <td>L1_S24_D1826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>847</th>\n",
       "      <td>S27</td>\n",
       "      <td>20461</td>\n",
       "      <td>L2_S27_D3186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>S17</td>\n",
       "      <td>20242</td>\n",
       "      <td>L0_S17_D432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>112</th>\n",
       "      <td>S15</td>\n",
       "      <td>20086</td>\n",
       "      <td>L0_S15_D395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>S19</td>\n",
       "      <td>20043</td>\n",
       "      <td>L0_S19_D456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>S18</td>\n",
       "      <td>19974</td>\n",
       "      <td>L0_S18_D437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>106</th>\n",
       "      <td>S14</td>\n",
       "      <td>19926</td>\n",
       "      <td>L0_S14_D372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122</th>\n",
       "      <td>S16</td>\n",
       "      <td>19783</td>\n",
       "      <td>L0_S16_D428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158</th>\n",
       "      <td>S22</td>\n",
       "      <td>13398</td>\n",
       "      <td>L0_S22_D563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>S21</td>\n",
       "      <td>13359</td>\n",
       "      <td>L0_S21_D469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>S23</td>\n",
       "      <td>13295</td>\n",
       "      <td>L0_S23_D669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1114</th>\n",
       "      <td>S45</td>\n",
       "      <td>10388</td>\n",
       "      <td>L3_S45_D4127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1059</th>\n",
       "      <td>S39</td>\n",
       "      <td>10388</td>\n",
       "      <td>L3_S39_D3966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1080</th>\n",
       "      <td>S41</td>\n",
       "      <td>10386</td>\n",
       "      <td>L3_S41_D4013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1127</th>\n",
       "      <td>S47</td>\n",
       "      <td>10385</td>\n",
       "      <td>L3_S47_D4180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1067</th>\n",
       "      <td>S40</td>\n",
       "      <td>10384</td>\n",
       "      <td>L3_S40_D3989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1154</th>\n",
       "      <td>S51</td>\n",
       "      <td>10383</td>\n",
       "      <td>L3_S51_D4261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1133</th>\n",
       "      <td>S48</td>\n",
       "      <td>10380</td>\n",
       "      <td>L3_S48_D4199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>S25</td>\n",
       "      <td>9075</td>\n",
       "      <td>L1_S25_D1864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1014</th>\n",
       "      <td>S31</td>\n",
       "      <td>6413</td>\n",
       "      <td>L3_S31_D3836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1150</th>\n",
       "      <td>S50</td>\n",
       "      <td>5316</td>\n",
       "      <td>L3_S50_D4254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1100</th>\n",
       "      <td>S43</td>\n",
       "      <td>5285</td>\n",
       "      <td>L3_S43_D4077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1110</th>\n",
       "      <td>S44</td>\n",
       "      <td>5181</td>\n",
       "      <td>L3_S44_D4116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1139</th>\n",
       "      <td>S49</td>\n",
       "      <td>5083</td>\n",
       "      <td>L3_S49_D4218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1057</th>\n",
       "      <td>S38</td>\n",
       "      <td>4615</td>\n",
       "      <td>L3_S38_D3957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1018</th>\n",
       "      <td>S32</td>\n",
       "      <td>4199</td>\n",
       "      <td>L3_S32_D3852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>S28</td>\n",
       "      <td>1433</td>\n",
       "      <td>L2_S28_D3249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1092</th>\n",
       "      <td>S42</td>\n",
       "      <td>2</td>\n",
       "      <td>L3_S42_D4041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1118</th>\n",
       "      <td>S46</td>\n",
       "      <td>0</td>\n",
       "      <td>L3_S46_D4135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     index       0       feature\n",
       "1054   S37  188967  L3_S37_D3949\n",
       "1003   S30  188856  L3_S30_D3781\n",
       "906    S29  188815  L3_S29_D3383\n",
       "1033   S34  188009  L3_S34_D3883\n",
       "1020   S33  187953  L3_S33_D3858\n",
       "12      S1  115960     L0_S1_D26\n",
       "49      S8  115937    L0_S8_D150\n",
       "1       S0  115932      L0_S0_D3\n",
       "1044   S36   96117  L3_S36_D3923\n",
       "1039   S35   92968  L3_S35_D3905\n",
       "34      S5   58441    L0_S5_D115\n",
       "37      S6   58434    L0_S6_D124\n",
       "20      S2   58378     L0_S2_D58\n",
       "32      S4   57667    L0_S4_D106\n",
       "26      S3   57663     L0_S3_D82\n",
       "41      S7   57654    L0_S7_D137\n",
       "138    S20   40018   L0_S20_D467\n",
       "102    S13   40011   L0_S13_D357\n",
       "92     S12   40007   L0_S12_D337\n",
       "53      S9   38879    L0_S9_D167\n",
       "76     S11   38793   L0_S11_D280\n",
       "67     S10   38622   L0_S10_D236\n",
       "815    S26   36772  L2_S26_D3074\n",
       "458    S24   22093  L1_S24_D1826\n",
       "847    S27   20461  L2_S27_D3186\n",
       "123    S17   20242   L0_S17_D432\n",
       "112    S15   20086   L0_S15_D395\n",
       "131    S19   20043   L0_S19_D456\n",
       "125    S18   19974   L0_S18_D437\n",
       "106    S14   19926   L0_S14_D372\n",
       "122    S16   19783   L0_S16_D428\n",
       "158    S22   13398   L0_S22_D563\n",
       "139    S21   13359   L0_S21_D469\n",
       "182    S23   13295   L0_S23_D669\n",
       "1114   S45   10388  L3_S45_D4127\n",
       "1059   S39   10388  L3_S39_D3966\n",
       "1080   S41   10386  L3_S41_D4013\n",
       "1127   S47   10385  L3_S47_D4180\n",
       "1067   S40   10384  L3_S40_D3989\n",
       "1154   S51   10383  L3_S51_D4261\n",
       "1133   S48   10380  L3_S48_D4199\n",
       "476    S25    9075  L1_S25_D1864\n",
       "1014   S31    6413  L3_S31_D3836\n",
       "1150   S50    5316  L3_S50_D4254\n",
       "1100   S43    5285  L3_S43_D4077\n",
       "1110   S44    5181  L3_S44_D4116\n",
       "1139   S49    5083  L3_S49_D4218\n",
       "1057   S38    4615  L3_S38_D3957\n",
       "1018   S32    4199  L3_S32_D3852\n",
       "864    S28    1433  L2_S28_D3249\n",
       "1092   S42       2  L3_S42_D4041\n",
       "1118   S46       0  L3_S46_D4135"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_not_null.drop_duplicates('index', inplace=True)\n",
    "count_not_null"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b815d516-f58f-4d8e-8b5d-11bc4e28cd78",
   "metadata": {},
   "source": [
    "Примем названия станций за индексы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "d72e0828-ba60-4ffa-8e6c-3532621ed742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(52, 3)"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_not_null.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "5f449763-62b7-48bd-b4ee-75f1fd8183e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>feature</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>index</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>S37</th>\n",
       "      <td>188967</td>\n",
       "      <td>L3_S37_D3949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S30</th>\n",
       "      <td>188856</td>\n",
       "      <td>L3_S30_D3781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S29</th>\n",
       "      <td>188815</td>\n",
       "      <td>L3_S29_D3383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S34</th>\n",
       "      <td>188009</td>\n",
       "      <td>L3_S34_D3883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S33</th>\n",
       "      <td>187953</td>\n",
       "      <td>L3_S33_D3858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S1</th>\n",
       "      <td>115960</td>\n",
       "      <td>L0_S1_D26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S8</th>\n",
       "      <td>115937</td>\n",
       "      <td>L0_S8_D150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S0</th>\n",
       "      <td>115932</td>\n",
       "      <td>L0_S0_D3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S36</th>\n",
       "      <td>96117</td>\n",
       "      <td>L3_S36_D3923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S35</th>\n",
       "      <td>92968</td>\n",
       "      <td>L3_S35_D3905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S5</th>\n",
       "      <td>58441</td>\n",
       "      <td>L0_S5_D115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S6</th>\n",
       "      <td>58434</td>\n",
       "      <td>L0_S6_D124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S2</th>\n",
       "      <td>58378</td>\n",
       "      <td>L0_S2_D58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S4</th>\n",
       "      <td>57667</td>\n",
       "      <td>L0_S4_D106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S3</th>\n",
       "      <td>57663</td>\n",
       "      <td>L0_S3_D82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S7</th>\n",
       "      <td>57654</td>\n",
       "      <td>L0_S7_D137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S20</th>\n",
       "      <td>40018</td>\n",
       "      <td>L0_S20_D467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S13</th>\n",
       "      <td>40011</td>\n",
       "      <td>L0_S13_D357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S12</th>\n",
       "      <td>40007</td>\n",
       "      <td>L0_S12_D337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S9</th>\n",
       "      <td>38879</td>\n",
       "      <td>L0_S9_D167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S11</th>\n",
       "      <td>38793</td>\n",
       "      <td>L0_S11_D280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S10</th>\n",
       "      <td>38622</td>\n",
       "      <td>L0_S10_D236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S26</th>\n",
       "      <td>36772</td>\n",
       "      <td>L2_S26_D3074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S24</th>\n",
       "      <td>22093</td>\n",
       "      <td>L1_S24_D1826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S27</th>\n",
       "      <td>20461</td>\n",
       "      <td>L2_S27_D3186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S17</th>\n",
       "      <td>20242</td>\n",
       "      <td>L0_S17_D432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S15</th>\n",
       "      <td>20086</td>\n",
       "      <td>L0_S15_D395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S19</th>\n",
       "      <td>20043</td>\n",
       "      <td>L0_S19_D456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S18</th>\n",
       "      <td>19974</td>\n",
       "      <td>L0_S18_D437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S14</th>\n",
       "      <td>19926</td>\n",
       "      <td>L0_S14_D372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S16</th>\n",
       "      <td>19783</td>\n",
       "      <td>L0_S16_D428</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S22</th>\n",
       "      <td>13398</td>\n",
       "      <td>L0_S22_D563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S21</th>\n",
       "      <td>13359</td>\n",
       "      <td>L0_S21_D469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S23</th>\n",
       "      <td>13295</td>\n",
       "      <td>L0_S23_D669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S45</th>\n",
       "      <td>10388</td>\n",
       "      <td>L3_S45_D4127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S39</th>\n",
       "      <td>10388</td>\n",
       "      <td>L3_S39_D3966</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S41</th>\n",
       "      <td>10386</td>\n",
       "      <td>L3_S41_D4013</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S47</th>\n",
       "      <td>10385</td>\n",
       "      <td>L3_S47_D4180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S40</th>\n",
       "      <td>10384</td>\n",
       "      <td>L3_S40_D3989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S51</th>\n",
       "      <td>10383</td>\n",
       "      <td>L3_S51_D4261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S48</th>\n",
       "      <td>10380</td>\n",
       "      <td>L3_S48_D4199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S25</th>\n",
       "      <td>9075</td>\n",
       "      <td>L1_S25_D1864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S31</th>\n",
       "      <td>6413</td>\n",
       "      <td>L3_S31_D3836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S50</th>\n",
       "      <td>5316</td>\n",
       "      <td>L3_S50_D4254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S43</th>\n",
       "      <td>5285</td>\n",
       "      <td>L3_S43_D4077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S44</th>\n",
       "      <td>5181</td>\n",
       "      <td>L3_S44_D4116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S49</th>\n",
       "      <td>5083</td>\n",
       "      <td>L3_S49_D4218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S38</th>\n",
       "      <td>4615</td>\n",
       "      <td>L3_S38_D3957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S32</th>\n",
       "      <td>4199</td>\n",
       "      <td>L3_S32_D3852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S28</th>\n",
       "      <td>1433</td>\n",
       "      <td>L2_S28_D3249</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S42</th>\n",
       "      <td>2</td>\n",
       "      <td>L3_S42_D4041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>S46</th>\n",
       "      <td>0</td>\n",
       "      <td>L3_S46_D4135</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0       feature\n",
       "index                      \n",
       "S37    188967  L3_S37_D3949\n",
       "S30    188856  L3_S30_D3781\n",
       "S29    188815  L3_S29_D3383\n",
       "S34    188009  L3_S34_D3883\n",
       "S33    187953  L3_S33_D3858\n",
       "S1     115960     L0_S1_D26\n",
       "S8     115937    L0_S8_D150\n",
       "S0     115932      L0_S0_D3\n",
       "S36     96117  L3_S36_D3923\n",
       "S35     92968  L3_S35_D3905\n",
       "S5      58441    L0_S5_D115\n",
       "S6      58434    L0_S6_D124\n",
       "S2      58378     L0_S2_D58\n",
       "S4      57667    L0_S4_D106\n",
       "S3      57663     L0_S3_D82\n",
       "S7      57654    L0_S7_D137\n",
       "S20     40018   L0_S20_D467\n",
       "S13     40011   L0_S13_D357\n",
       "S12     40007   L0_S12_D337\n",
       "S9      38879    L0_S9_D167\n",
       "S11     38793   L0_S11_D280\n",
       "S10     38622   L0_S10_D236\n",
       "S26     36772  L2_S26_D3074\n",
       "S24     22093  L1_S24_D1826\n",
       "S27     20461  L2_S27_D3186\n",
       "S17     20242   L0_S17_D432\n",
       "S15     20086   L0_S15_D395\n",
       "S19     20043   L0_S19_D456\n",
       "S18     19974   L0_S18_D437\n",
       "S14     19926   L0_S14_D372\n",
       "S16     19783   L0_S16_D428\n",
       "S22     13398   L0_S22_D563\n",
       "S21     13359   L0_S21_D469\n",
       "S23     13295   L0_S23_D669\n",
       "S45     10388  L3_S45_D4127\n",
       "S39     10388  L3_S39_D3966\n",
       "S41     10386  L3_S41_D4013\n",
       "S47     10385  L3_S47_D4180\n",
       "S40     10384  L3_S40_D3989\n",
       "S51     10383  L3_S51_D4261\n",
       "S48     10380  L3_S48_D4199\n",
       "S25      9075  L1_S25_D1864\n",
       "S31      6413  L3_S31_D3836\n",
       "S50      5316  L3_S50_D4254\n",
       "S43      5285  L3_S43_D4077\n",
       "S44      5181  L3_S44_D4116\n",
       "S49      5083  L3_S49_D4218\n",
       "S38      4615  L3_S38_D3957\n",
       "S32      4199  L3_S32_D3852\n",
       "S28      1433  L2_S28_D3249\n",
       "S42         2  L3_S42_D4041\n",
       "S46         0  L3_S46_D4135"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_not_null = count_not_null.set_index('index')\n",
    "count_not_null"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98bf775-2c65-4575-89b6-b940d487223e",
   "metadata": {},
   "source": [
    "Данный участок кода выполняет кодирование для каждого объекта по новым признакам: если в ячейке стоит единица, значит объект проходил через данную станцию. Ноль говорит о том, что объекта не было на данной станции S, либо данные об этом потеряны. Параллельно с этим вычисляются признаки start_st и end_st, которые соответствуют номерам начальной и конечной станции."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "7c6825c4-0cba-48a6-bac0-4a529bc46a48",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>S0</th>\n",
       "      <th>S1</th>\n",
       "      <th>S10</th>\n",
       "      <th>S11</th>\n",
       "      <th>S12</th>\n",
       "      <th>S13</th>\n",
       "      <th>S14</th>\n",
       "      <th>S15</th>\n",
       "      <th>S16</th>\n",
       "      <th>...</th>\n",
       "      <th>S49</th>\n",
       "      <th>S5</th>\n",
       "      <th>S50</th>\n",
       "      <th>S51</th>\n",
       "      <th>S6</th>\n",
       "      <th>S7</th>\n",
       "      <th>S8</th>\n",
       "      <th>S9</th>\n",
       "      <th>start_st</th>\n",
       "      <th>end_st</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199995</th>\n",
       "      <td>399894</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>31</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199996</th>\n",
       "      <td>399896</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199997</th>\n",
       "      <td>399897</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199998</th>\n",
       "      <td>399898</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199999</th>\n",
       "      <td>399899</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200000 rows × 55 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id  S0  S1  S10  S11  S12  S13  S14  S15  S16  ...  S49  S5  S50  \\\n",
       "0            4   1   1    1    0    1    0    0    1    1  ...    0   0    0   \n",
       "1            6   0   0    0    0    0    0    0    0    0  ...    0   0    0   \n",
       "2            7   1   1    1    0    0    1    1    0    1  ...    0   0    0   \n",
       "3            9   1   1    1    0    1    0    0    1    1  ...    0   0    0   \n",
       "4           11   1   1    0    1    1    0    0    1    1  ...    0   0    0   \n",
       "...        ...  ..  ..  ...  ...  ...  ...  ...  ...  ...  ...  ...  ..  ...   \n",
       "199995  399894   0   0    0    0    0    0    0    0    0  ...    0   1    0   \n",
       "199996  399896   0   0    0    0    0    0    0    0    0  ...    0   0    0   \n",
       "199997  399897   1   1    1    0    1    0    1    0    1  ...    0   0    0   \n",
       "199998  399898   1   1    0    1    1    0    1    0    1  ...    0   0    0   \n",
       "199999  399899   0   0    0    0    0    0    0    0    0  ...    0   0    0   \n",
       "\n",
       "        S51  S6  S7  S8  S9  start_st  end_st  \n",
       "0         0   0   0   0   0         0      42  \n",
       "1         0   0   0   0   0         2      42  \n",
       "2         0   0   0   0   0         0      42  \n",
       "3         0   0   0   0   0         0      42  \n",
       "4         0   0   0   0   0         0      42  \n",
       "...     ...  ..  ..  ..  ..       ...     ...  \n",
       "199995    1   1   0   1   1        31       9  \n",
       "199996    0   0   0   0   0        30      42  \n",
       "199997    0   0   0   0   0         0      42  \n",
       "199998    0   0   0   0   0         0      42  \n",
       "199999    0   0   0   0   0        30      42  \n",
       "\n",
       "[200000 rows x 55 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_features = None\n",
    "new_cols = sorted(count_not_null.index.to_list(), reverse=False)\n",
    "last_cols =  count_not_null['feature'].to_list()\n",
    "for chunk in pd.read_csv('datasets/train_date.csv', usecols=['Id'] + last_cols, chunksize=60000, low_memory=False, nrows=200000):\n",
    "    chunk.columns = ['Id'] + new_cols\n",
    "    chunk['start_st'] = -1\n",
    "    chunk['end_st'] = -1\n",
    "    for station in new_cols:\n",
    "        full_col = station\n",
    "        chunk[station] = 1 * (chunk[full_col].astype('float64') >= 0)\n",
    "        chunk.loc[(chunk['start_st'] == -1) & (chunk['Id'].isin(chunk[chunk[station] > 0].Id)), 'start_st'] = int(station[1:])\n",
    "        chunk.loc[(chunk['Id'].isin(chunk[chunk[station] > 0].Id)), 'end_st'] = int(station[1:])\n",
    "    new_features = pd.concat([new_features, chunk])\n",
    "    del chunk\n",
    "new_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "181e2dae-3569-4e4b-9dba-b394994cfe50",
   "metadata": {},
   "source": [
    "В следующем блоке происходят аналогичные вещи – формируются новые признаки, которые в будущем могут улучшить качество работы модели: mindate, maxdate – минимальное и максимальное значение времени для данного объекта (del_t – разница между этими значениями), min_time_st – номер станции соответствующий mindate, max_time_st – тоже самое но относится к maxdate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "d336627c-9809-4cd7-85b6-3dfd3bd477c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>mindate</th>\n",
       "      <th>maxdate</th>\n",
       "      <th>min_time_st</th>\n",
       "      <th>max_time_st</th>\n",
       "      <th>del_t</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>82.24</td>\n",
       "      <td>87.29</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>5.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>1313.12</td>\n",
       "      <td>1315.75</td>\n",
       "      <td>12</td>\n",
       "      <td>33</td>\n",
       "      <td>2.63</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>1618.70</td>\n",
       "      <td>1624.42</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>5.72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9</td>\n",
       "      <td>1149.20</td>\n",
       "      <td>1154.16</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>4.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>602.64</td>\n",
       "      <td>606.02</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>3.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1183742</th>\n",
       "      <td>2367490</td>\n",
       "      <td>1239.90</td>\n",
       "      <td>1244.04</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>4.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1183743</th>\n",
       "      <td>2367491</td>\n",
       "      <td>624.22</td>\n",
       "      <td>626.66</td>\n",
       "      <td>12</td>\n",
       "      <td>36</td>\n",
       "      <td>2.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1183744</th>\n",
       "      <td>2367492</td>\n",
       "      <td>1482.18</td>\n",
       "      <td>1490.61</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>8.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1183745</th>\n",
       "      <td>2367493</td>\n",
       "      <td>608.83</td>\n",
       "      <td>610.75</td>\n",
       "      <td>0</td>\n",
       "      <td>33</td>\n",
       "      <td>1.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1183746</th>\n",
       "      <td>2367495</td>\n",
       "      <td>937.61</td>\n",
       "      <td>942.33</td>\n",
       "      <td>0</td>\n",
       "      <td>37</td>\n",
       "      <td>4.72</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1183747 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Id  mindate  maxdate  min_time_st  max_time_st  del_t\n",
       "0              4    82.24    87.29            0           35   5.05\n",
       "1              6  1313.12  1315.75           12           33   2.63\n",
       "2              7  1618.70  1624.42            0           33   5.72\n",
       "3              9  1149.20  1154.16            0           36   4.96\n",
       "4             11   602.64   606.02            0           36   3.38\n",
       "...          ...      ...      ...          ...          ...    ...\n",
       "1183742  2367490  1239.90  1244.04            0           33   4.14\n",
       "1183743  2367491   624.22   626.66           12           36   2.44\n",
       "1183744  2367492  1482.18  1490.61            0           34   8.43\n",
       "1183745  2367493   608.83   610.75            0           33   1.92\n",
       "1183746  2367495   937.61   942.33            0           37   4.72\n",
       "\n",
       "[1183747 rows x 6 columns]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "minmaxfeatures = None\n",
    "for chunk in pd.read_csv('datasets/train_date.csv', usecols=['Id'] + last_cols, chunksize=60000, low_memory=False):\n",
    "    l_cols = chunk.columns.drop('Id').values\n",
    "    df_chunk = chunk[['Id']].copy()\n",
    "    df_chunk['mindate'] = chunk[l_cols].min(axis=1).values\n",
    "    df_chunk['maxdate'] = chunk[l_cols].max(axis=1).values\n",
    "    df_chunk['min_time_st'] =  chunk[l_cols].idxmin(axis = 1).apply(lambda s: int(s.split('_')[1][1:]) if s is not np.nan else -1)\n",
    "    df_chunk['max_time_st'] =  chunk[l_cols].idxmax(axis = 1).apply(lambda s: int(s.split('_')[1][1:]) if s is not np.nan else -1)\n",
    "    df_chunk['del_t'] =  df_chunk['maxdate'] - df_chunk['mindate']\n",
    "    minmaxfeatures = pd.concat([minmaxfeatures, df_chunk])\n",
    "    del chunk\n",
    "minmaxfeatures"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddbc8ed7-8abd-4d14-aff9-f775e60cfd7c",
   "metadata": {},
   "source": [
    "Объединим временные признаки в один большой массив X_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "e34d09b1-f8e8-4e03-8962-c3c6e63af0e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  82.24,   87.29,    0.  , ...,    0.  ,    0.  ,   42.  ],\n",
       "       [1313.12, 1315.75,   12.  , ...,    0.  ,    2.  ,   42.  ],\n",
       "       [1618.7 , 1624.42,    0.  , ...,    0.  ,    0.  ,   42.  ],\n",
       "       ...,\n",
       "       [ 675.79,  677.5 ,    0.  , ...,    0.  ,    0.  ,   42.  ],\n",
       "       [1225.57, 1226.83,    0.  , ...,    0.  ,    0.  ,   42.  ],\n",
       "       [ 964.76,  988.84,   24.  , ...,    0.  ,   30.  ,   42.  ]])"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_time = pd.merge(minmaxfeatures, new_features).drop('Id', axis=1)\n",
    "X_time = df_time.to_numpy()\n",
    "X_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "72320086-e8c4-4b46-a726-4b1b1f12a77c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200000, 968), (200000,))"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_num = df_num.iloc[:, :-1].to_numpy()\n",
    "y = df_num['Response'].to_numpy()\n",
    "X_num.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d2771e-9a68-4841-b87d-b4d8576591bf",
   "metadata": {},
   "source": [
    "# Понижение размерности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "d1169596-976b-455e-a699-24b3ad970967",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:57:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "imp_time = calc_feature_imp(X=X_time, y=y)\n",
    "imp_cat = calc_feature_imp(X=X_categorical, y=y)\n",
    "imp_num = calc_feature_imp(X=X_num, y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "a1bb70c9-3dce-4424-b403-0c84bb19242b",
   "metadata": {},
   "outputs": [],
   "source": [
    "l_imp_time = get_sorted_labels(labels=df_time.columns, features_imp = imp_time)\n",
    "l_imp_cat = imp_cat.argsort()[::-1]\n",
    "l_imp_num = get_sorted_labels(labels=df_num.columns[:-1], features_imp = imp_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "1715a8ce-832f-4123-aeeb-1025ef431c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_sort_time = df_time[l_imp_time].to_numpy()\n",
    "X_sort_cat = X_categorical[:, l_imp_cat]\n",
    "X_sort_num = df_num[l_imp_num].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "1365ce29-8095-452b-8f54-2a3070918f98",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200000, 127)"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_sort_cat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "8da4c636-7041-4529-ae78-0d7d5c3f6d23",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[00:57:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:57:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:58:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:58:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:58:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:58:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:58:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:58:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:58:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:58:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:58:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:58:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:58:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:58:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:58:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:58:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:58:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:58:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:58:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:58:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:58:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:58:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:58:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:58:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:58:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:58:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:58:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:58:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:58:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:58:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:58:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:58:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:58:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:58:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:58:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:58:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:58:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:58:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:58:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:58:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:58:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:58:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:58:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:58:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:58:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:58:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:58:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:58:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:58:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:58:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:58:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:58:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:58:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:58:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:58:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:58:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:58:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:58:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:58:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:58:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:58:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:58:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:58:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:58:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:58:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:58:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:58:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:58:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:58:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:58:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:58:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:58:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:58:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:58:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:58:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:58:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:58:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:58:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:58:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:58:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:58:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:58:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:58:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:58:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:58:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:58:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:58:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:58:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:59:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:59:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:59:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:59:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:59:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:59:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:59:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:59:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:59:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:59:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:59:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:59:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:59:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:59:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:59:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:59:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:59:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:59:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:59:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:59:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:59:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:59:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:59:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:59:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:59:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:59:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:59:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:59:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:59:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:59:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:59:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:59:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:59:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:59:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:59:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:59:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:59:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:59:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:59:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:59:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:59:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:59:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:59:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:59:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:59:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:59:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:59:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:59:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:59:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:59:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:59:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:59:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:59:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:59:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:59:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:59:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:59:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:59:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:59:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:59:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:59:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:59:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:59:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:59:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[00:59:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:00:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:00:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:00:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:00:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:00:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:00:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:00:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:00:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:00:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:00:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:00:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:00:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:00:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:00:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:00:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:00:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:00:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:00:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:00:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:00:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:00:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:00:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:00:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:00:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:00:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:00:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:00:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:00:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:00:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:00:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:00:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:00:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:00:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:00:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:00:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:00:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:00:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:00:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:00:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:00:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:00:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:00:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:00:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:00:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:00:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:00:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:00:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:00:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:00:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:00:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:00:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:00:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:00:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:00:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:00:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:01:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:01:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:01:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:01:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:01:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:01:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:01:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:01:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:01:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[01:01:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([0.        , 0.        , 0.        , 0.        , 0.06960442,\n",
       "        0.0919696 , 0.0750319 , 0.07076487, 0.07601046, 0.0773536 ,\n",
       "        0.07621002, 0.08374162, 0.07235015, 0.07076487, 0.07351355,\n",
       "        0.09597077, 0.12057407, 0.0855418 , 0.10453626, 0.10954543,\n",
       "        0.10695625, 0.10345651, 0.10183609, 0.06949031, 0.06949031,\n",
       "        0.08326778, 0.09418776, 0.09147278, 0.08848503, 0.09147278,\n",
       "        0.100572  , 0.09754858, 0.06497867, 0.09754858, 0.0773536 ,\n",
       "        0.0855418 , 0.0899431 , 0.06712666, 0.07310719, 0.10183609,\n",
       "        0.08521689, 0.11275954, 0.09032555, 0.06949515, 0.09754858,\n",
       "        0.09308018, 0.0787673 , 0.0787673 , 0.0787673 , 0.0787673 ,\n",
       "        0.0787673 , 0.0787673 , 0.0787673 , 0.0787673 , 0.0787673 ,\n",
       "        0.0787673 , 0.0787673 , 0.10345651, 0.10345651]),\n",
       " array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " array([0.        , 0.        , 0.06029184, 0.06467617, 0.06066585,\n",
       "        0.06359205, 0.05374348, 0.06066585, 0.05691975, 0.05435196,\n",
       "        0.06798378, 0.09610604, 0.08373453, 0.0944646 , 0.11232467,\n",
       "        0.10674634, 0.09844191, 0.11877946, 0.1206054 , 0.09308018,\n",
       "        0.11972473, 0.10994327, 0.12386681, 0.12261426, 0.12413703,\n",
       "        0.11379308, 0.10596221, 0.12905778, 0.11312005, 0.11690504,\n",
       "        0.11312005, 0.10596221, 0.11275954, 0.10754939, 0.13910753,\n",
       "        0.10596221, 0.13413603, 0.12743574, 0.11842799, 0.11481169,\n",
       "        0.08374162, 0.10183609, 0.09880436, 0.09880436, 0.09106908,\n",
       "        0.08885441, 0.08392998, 0.09164652, 0.11334049, 0.07988817,\n",
       "        0.07123785, 0.18793542, 0.17200484, 0.16088265, 0.18843836,\n",
       "        0.19193391, 0.1889303 , 0.18332077, 0.2057589 , 0.17027775,\n",
       "        0.20420323, 0.17366241, 0.18621907, 0.18668632, 0.18621907,\n",
       "        0.20761861, 0.20761861, 0.18668632, 0.19666786, 0.19282524,\n",
       "        0.18638441, 0.17614227, 0.20394723, 0.18726425, 0.19395624,\n",
       "        0.2062138 , 0.18668632, 0.20420323, 0.23131624, 0.19399836,\n",
       "        0.19399836, 0.19335802, 0.1826752 , 0.20420323, 0.17280866,\n",
       "        0.17280866, 0.1744733 , 0.19985133, 0.19596136, 0.20962583,\n",
       "        0.19399836, 0.16697602, 0.19688653, 0.17278772, 0.15242299,\n",
       "        0.18806821, 0.19453984, 0.17526521, 0.1638441 , 0.18498115,\n",
       "        0.17258612, 0.15447898, 0.16381858, 0.16441444, 0.16441444,\n",
       "        0.15447898, 0.17526521, 0.1524873 , 0.1562298 , 0.16885568,\n",
       "        0.15280185, 0.1562298 , 0.15249897, 0.17620791, 0.17166761,\n",
       "        0.19023945, 0.18806821, 0.17771124, 0.17860496, 0.18621907,\n",
       "        0.1744733 , 0.17771124, 0.17561853, 0.13406054, 0.18570794,\n",
       "        0.14279697, 0.16860042, 0.16339339, 0.1524873 , 0.15116825,\n",
       "        0.16381858, 0.14505568, 0.13894311, 0.17079868, 0.18148156,\n",
       "        0.18148156, 0.16538572, 0.15563448, 0.17620791, 0.18588401,\n",
       "        0.15897908, 0.13736421, 0.16773429, 0.19629988, 0.15685465,\n",
       "        0.1404474 , 0.11835216, 0.17516862, 0.16441444, 0.16441444,\n",
       "        0.15448807, 0.13406054, 0.16073204, 0.16254274, 0.14966656,\n",
       "        0.16635064, 0.17280866, 0.14526171, 0.16254274, 0.17079868,\n",
       "        0.19209195, 0.1534346 , 0.15164595, 0.14580325, 0.16182076,\n",
       "        0.16339339, 0.14580325, 0.16182076, 0.14966656, 0.16563743,\n",
       "        0.17926668, 0.14526171, 0.17946397, 0.17516862, 0.13427018,\n",
       "        0.15803019, 0.14580325, 0.14697658, 0.1725992 , 0.14175142,\n",
       "        0.14175142, 0.15528634, 0.12914868, 0.16002658, 0.16002658,\n",
       "        0.17928183, 0.16635064, 0.1439778 , 0.1439778 , 0.1439778 ,\n",
       "        0.15171389, 0.14697658, 0.13249322, 0.15720499, 0.15447898,\n",
       "        0.12933631, 0.15116825, 0.15116825, 0.15112323, 0.15803019,\n",
       "        0.16441444, 0.14559091, 0.13887746, 0.17280866, 0.17258612,\n",
       "        0.15171389, 0.13779035, 0.16804094, 0.15606711, 0.15112323,\n",
       "        0.122074  , 0.13267213, 0.15720499, 0.14091701, 0.13779035,\n",
       "        0.13972989, 0.14175142, 0.15059139, 0.12914868, 0.16381858,\n",
       "        0.1386935 , 0.17704576, 0.14386092, 0.13779035, 0.14088521,\n",
       "        0.15384542, 0.14559091, 0.13659861, 0.15384542, 0.13267213,\n",
       "        0.13659861, 0.14769799, 0.13459358, 0.15059139, 0.1737842 ,\n",
       "        0.14769799, 0.14769799, 0.12760252, 0.16563743, 0.13592738,\n",
       "        0.14697658, 0.16441444]))"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "time_met = metrics_on_feature_count(X=X_sort_time, y=y, max_count=X_sort_time.shape[1])\n",
    "cat_met = metrics_on_feature_count(X=X_sort_cat, y=y, max_count=X_sort_cat.shape[1] // 4)\n",
    "num_met = metrics_on_feature_count(X=X_sort_num, y=y, max_count=X_sort_num.shape[1] // 4)\n",
    "time_met, cat_met, num_met"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "24f56e31-855a-40e2-a96f-2b9eee5f0b0a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'countmax numeric': 79, 'countmax categorical': 1, 'countmax time': 17}"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1008x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_metric_dep_f_count(num_x=range(1, X_sort_num.shape[1] // 4 + 1), \n",
    "                        num_y=num_met, \n",
    "                        cat_x=range(1, X_sort_cat.shape[1] // 4 + 1), \n",
    "                        cat_y=cat_met, \n",
    "                        time_x=range(1, X_sort_time.shape[1] + 1), \n",
    "                        time_y=time_met)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "ed201a4b-5c37-465e-94da-405ac54ce370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.   ,  1.   ,  0.   , ...,  0.038, -0.03 ,  0.   ],\n",
       "       [ 0.   ,  1.   ,  0.   , ..., -0.036,  0.   , -0.134],\n",
       "       [ 0.   ,  1.   ,  0.   , ...,  0.119, -0.077,  0.   ],\n",
       "       ...,\n",
       "       [ 0.   ,  1.   ,  0.   , ..., -0.017, -0.003,  0.   ],\n",
       "       [ 0.   ,  1.   ,  0.   , ...,  0.001,  0.   ,  0.   ],\n",
       "       [ 0.   ,  1.   ,  1.   , ...,  0.043,  0.   ,  0.   ]])"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = np.concatenate((X_sort_time[:, :20], X_sort_num[:, :79]), axis=1)\n",
    "X = np.nan_to_num(X)\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00ba9d38-e440-4ac4-b371-ebfd4eed1368",
   "metadata": {},
   "source": [
    "# Построение модели"
   ]
  },
  {
   "attachments": {
    "d69d4cdc-f3ba-41af-bd78-de3d853902b5.png": {
     "image/png": "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"
    },
    "fc08d083-c674-47a9-9eaf-1c2bb0611333.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "id": "244f7321-57d3-4c7f-8372-70ee85ed4e36",
   "metadata": {},
   "source": [
    "Сформулируем задачу машинного обучения. Пусть имеем матрицу объектов-признаков X; каждая строка соответствует своему объекту (объектов всего у нас n), а столбец значению признака для каждого объекта (признаков всего m). Также имеем таргеты для каждого объекта из матрицы X (для каждой строки). \n",
    "\n",
    "![image.png](attachment:d69d4cdc-f3ba-41af-bd78-de3d853902b5.png)\n",
    "\n",
    "Необходимо найти такую модель a, которая максимально приближает зависимость y: X→Y (где y - искомая зависимость, Y – множество значений y).\n",
    "\n",
    "Суть алгоритма градиентного бустинга заключается в последовательном построении ансамбля $a_m\\left(x\\right)$, в котором каждая последующая модель ${\\grave{f}}_k(x)$ минимизирует ошибку предыдущих. Величина m – количество моделей, лежащих в данный момент в ансамбле, x – входной вектор признаков объкекта.\n",
    "\n",
    "$$a_m\\left(x\\right)=\\sum_{k=1}^{m}{{\\grave{f}}_k(x)};$$\n",
    "\n",
    "Обычно за первую модель принимается какое-либо константное значение $\\zeta$ - это может быть среднее значение вектора y для задачи регрессии, или наиболее частая метка класса в обучающей выборке для задач классификации.  \n",
    "\n",
    "$${\\grave{f}}_1\\left(x\\right)=\\zeta$$\n",
    "\n",
    "Далее данная модель помещается в ансамбль $a(x)$.\n",
    "При построении ансамбля также необходимо выбрать функцию потерь $L\\left(y_{i\\ },a_s\\right)$, по которой можно будет определить, насколько ансамбль ошибается. Наиболее часто применяют квадратичную функцию потерь $MSE(y_{i\\ },a_s)$. Это связано с тем, что она непрерывна и является гладкой, что позволяет ее без проблем дифференцировать.\n",
    "\n",
    "$$L\\left(y_{i\\ },a_s\\right)=MSE(y_{i\\ },a_s)={(y_{i\\ }-a_s)}^2$$\n",
    "\n",
    "Сумма ошибок для всех элементов выборки называется эмпирическим риском $\\mathcal{L}$.\n",
    "\n",
    "$$\\mathcal{L}(y_\\ ,a_s)=\\sum_{i=1}^{n}L\\left(y_{i\\ },a_s\\right)$$\n",
    "\n",
    "Все модели ансамбля (кроме первой) считаются по следующему алгоритму. Пусть ансамбль включает в себя t моделей. \n",
    "\n",
    "$$a_t\\left(x\\right)=\\sum_{k=1}^{t}{{\\grave{f}}_k(x)}$$\n",
    "\n",
    "Тогда для построения ${\\grave{f}}_{t+1}(x)$ выполним следующие действия:\n",
    "\n",
    "Вычислим частные производные функции потерь по предсказаниям ансамбля для каждого объекта выборки. Фактически мы строим вектор в пространстве, где каждая ось соответствует своему объекту в обучающей выборке. Полученный вектор умножим на минус 1 для получения антиградиента функции потерь $g$. Так как мы используем $MSE$, то антиградиент будет считаться следующим образом:\n",
    "\n",
    "$$g=-\\left(\\begin{matrix}\\frac{\\partial L\\left(y_1,\\ a_t\\left(x_1\\right)\\right)}{\\partial a_t\\left(x_1\\right)}\\\\\\vdots\\\\\\frac{\\partial L\\left(y_n,\\ a_t\\left(x_n\\right)\\right)}{\\partial a_t\\left(x_n\\right)}\\\\\\end{matrix}\\right)=-\\left(\\begin{matrix}\\frac{\\partial MSE\\left(y_{1\\ },a_t\\left(x_1\\right)\\right)}{\\partial a_t\\left(x_1\\right)}\\\\\\vdots\\\\\\frac{\\partial MSE\\left(y_{n\\ },a_t\\left(x_n\\right)\\right)}{\\partial a_t\\left(x_n\\right)}\\\\\\end{matrix}\\right)=\\left(\\begin{matrix}2(y_1-a_t\\left(x_1\\right))\\\\\\vdots\\\\2(y_n-a_t\\left(x_n\\right))\\\\\\end{matrix}\\right)$$\n",
    "\n",
    "Обучим новую модель $h$ на таргетах, соответствующих значениям $g$. Так как антиградиент указывает на направление уменьшения функции (в нашем случае - ошибки), то новая модель $h $ будет компенсировать ошибку, оставшуюся после обучения предыдущих моделей, повышая точность предсказаний всего ансамбля в целом.  В роли $h$ могут выступать любые алгоритмы классического машинного обучения (линейная регрессия, классификация, решающее дерево). В данной работе в качестве $h$ берется решающее дерево, $θ_(t+1)$ – параметры этой модели (дерева). \n",
    "\n",
    "$$\\mathcal{L}\\left(g,h\\right)=\\sum_{i=1}^{n}{L\\left(g_i,h(x_i,\\theta_{t+1})\\right);}$$\n",
    "\n",
    "$${\\underset{\\theta_{t+1}}{\\mathrm{argmin}}}$$\n",
    "\n",
    "$$\\theta_{t+1}={\\underset{\\theta_{t+1}}{\\mathrm{argmin}}}{\\mathcal{L}\\left(g,h(X,\\ \\theta_{t+1})\\right)}={\\underset{\\theta_{t+1}}{\\mathrm{argmin}}}\\sum_{i=1}^{n}L\\left(g_i,h(x_i,\\theta_{t+1})\\right)$$\n",
    "\n",
    "После подбора всех параметров построенная модель добавляется к исходному ансамблю (веса новой модели не указываются, так как они больше меняться не будут).\n",
    "\n",
    "$$a_{t+1}\\left(x\\right)=a_t\\left(x\\right)+{\\grave{f}}_{t+1}\\left(x_i\\right)$$\n",
    "\n",
    "\n",
    "Разобьём выборку X на обучающую X_train и контрольную выборку X_test. Контрольная выборка играет ключевую роль, так как в ней содержится информация, которую модель не увидит во время своего обучения. На основе частоты правильных ответов модели при пропускании через нее этих данных делается вывод о ее качестве. Функция (или алгоритм), оценивающая качество работы модели называется метрикой. \n",
    "\n",
    "В данной работе будет использоваться корреляция Мэтьюса (MCC) в качестве основной метрики. Где: True positive (TP) – количество ответов модели, где истинная метка равна 1 и совпала с предсказанной; True negative (TN) – число объектов, где истинная метка равна -1 и совпала с предсказанной; False negative (FN) – количество примеров, где истинная метка равна 1 и не совпала с предсказанной. False positive (FP) соответствует ответам модели, при которых истинная метка равна -1 и не совпала с предсказанной.\n",
    "![image.png](attachment:fc08d083-c674-47a9-9eaf-1c2bb0611333.png)\n",
    " \n",
    "Мы также возьмем некоторые побочные метрики, которые могут оказаться полезны: ROC (ROC-AUC); Precision (точность), Recall (полнота); accuracy (точность, в основе которой доля правильных ответов модели). Первые три метрики прекрасно подходят для работы с несбалансированными выборками. Последняя крайне чувствительна к дисбалансу в выборке.\n",
    "\n",
    "Все вышеперечисленные величины вычисляются в функции show_metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "7cef7eb9-cca6-44fa-851c-a7f892ab1f6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03:27:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:576: \n",
      "Parameters: { \"random_seed\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[03:27:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy</th>\n",
       "      <th>matthews_corrcoef</th>\n",
       "      <th>roc_auc_score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.995</td>\n",
       "      <td>0.175</td>\n",
       "      <td>0.522</td>\n",
       "      <td>0.694</td>\n",
       "      <td>0.045</td>\n",
       "      <td>0.084</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy  matthews_corrcoef  roc_auc_score  precision  recall  f1_score\n",
       "0     0.995              0.175          0.522      0.694   0.045     0.084"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = X[:X.shape[0] // 2]\n",
    "y_train = y[:X.shape[0] // 2]\n",
    "X_test = X[X.shape[0] // 2:]\n",
    "y_test = y[X.shape[0] // 2:]\n",
    "model = XGBClassifier(use_label_encoder=False, tree_method=\"gpu_hist\", objective= 'binary:logistic', learning_rate=0.1, random_seed=234)\n",
    "model.fit(X_train, y_train)\n",
    "probas = model.predict_proba(X_test)[:, 1]\n",
    "y_pred = model.predict(X_test)\n",
    "show_metrics(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "e83e7d1b-7440-4ce6-884f-63f33a0f8749",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "plot_roc(y_true=y_test, y_pred=y_pred, y_pred_proba=probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "00352dbc-56d5-4dd1-8135-6542ec00e875",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_pr_rec_curve(y_true=y_test, y_pred=y_pred, y_pred_proba=probas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d20f47-d923-4c64-9adb-68b5948032bd",
   "metadata": {},
   "source": [
    "# Подобор гиперпараметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "f0e134f3-7237-4749-86f9-4d0bc7fd793b",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03:28:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:28:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:28:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:28:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:28:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:28:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:28:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:28:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:28:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:28:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:28:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:28:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:28:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:28:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:28:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:28:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:28:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:28:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:28:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:28:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:28:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:28:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:28:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:28:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:28:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:28:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:28:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:28:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:28:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:28:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:28:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:28:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:28:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:28:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:28:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:28:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:28:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:28:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:28:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:28:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:28:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:28:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:28:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:28:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:28:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:28:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:28:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:28:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:28:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:28:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:28:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:28:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:28:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:28:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:28:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:28:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:28:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:28:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:28:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:28:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:28:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:28:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:28:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:29:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:29:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:29:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:29:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:29:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:29:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:29:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:29:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:29:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:29:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:29:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:29:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:29:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:29:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:29:08] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:29:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:29:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:29:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:29:10] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:29:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:29:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:29:12] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:29:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:29:13] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:29:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:29:14] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:29:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:29:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:29:16] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:29:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:29:17] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:29:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:29:18] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:29:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:29:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:29:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:29:20] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:29:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:29:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:29:22] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:29:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:29:23] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:29:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:29:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:29:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:29:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:29:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[03:29:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "0.19256790655274425\n",
      "{'n_estimators': 7, 'max_depth': 8, 'learning_rate': 0.5000000000000001}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nprobas = model.predict_proba(X_test)[:, 1]\\ny_pred = model.predict(X_test)\\nshow_metrics(y_test, y_pred)\\n'"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_params = dict(\n",
    "        max_depth=range(2, 10),\n",
    "        learning_rate=np.arange(0.1, 1, 0.2),\n",
    "        n_estimators=range(2, 12, 1),\n",
    "        \n",
    "    \n",
    "    )\n",
    "\n",
    "model = XGBClassifier(use_label_encoder=False, \n",
    "                          tree_method=\"gpu_hist\",\n",
    "                          predictor='gpu_predictor',\n",
    "                          objective= 'binary:logistic')\n",
    "'''\n",
    "split_strategy = model_selection.StratifiedShuffleSplit(n_splits = 10, test_size = 0.3)\n",
    "for train_indexs, test_indexs in split_strategy.split(X, y):\n",
    "    X_train = X[train_indexs]\n",
    "    y_train = y[train_indexs]\n",
    "    X_test = X[test_indexs]\n",
    "    y_test = y[test_indexs]\n",
    "    model = XGBClassifier(use_label_encoder=False, \n",
    "                          **search_params,\n",
    "                          tree_method=\"gpu_hist\",\n",
    "                          predictor='gpu_predictor',\n",
    "                          objective= 'binary:logistic', \n",
    "                          random_seed=234)\n",
    "    model.fit(X_train, y_train)\n",
    "'''\n",
    "model = fit_and_find_hpar(model=model, \n",
    "                          param_dis=search_params,\n",
    "                          X=X,\n",
    "                          y=y,\n",
    "                          n_splits=11, \n",
    "                          test_size=0.3\n",
    "                         )\n",
    "\n",
    "print(model.best_score_)\n",
    "print(model.best_params_)\n",
    "\n",
    "'''\n",
    "probas = model.predict_proba(X_test)[:, 1]\n",
    "y_pred = model.predict(X_test)\n",
    "show_metrics(y_test, y_pred)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "227dada4-15e5-4b31-961b-c9aa6029fcd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best matthews_corrcoef: 0.19256790655274425\n",
      "{'n_estimators': 7, 'max_depth': 8, 'learning_rate': 0.5000000000000001}\n"
     ]
    }
   ],
   "source": [
    "print('best matthews_corrcoef:', model.best_score_)\n",
    "print(model.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b360ec-8607-4d19-b649-71ab0b97fe34",
   "metadata": {},
   "source": [
    "# Использованные источники\n",
    "https://www.kaggle.com/c/bosch-production-line-performance/overview\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc59f56c-90f1-4abb-b16c-c1ab9faba5d5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "StarLearn",
   "language": "python",
   "name": "ipykernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

